{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Workflow for Processing Construction Tenders and Floor Plans\n",
    "\n",
    "Dieses Notebook implementiert einen automatisierten Workflow zur Verarbeitung von Bauausschreibungen und Grundrissen gemäß der Projektbeschreibung im README.md.\n",
    "\n",
    "## Workflow-Übersicht:\n",
    "\n",
    "1. **Input Verification** - PDF-Text extrahieren (pdfminer/PyMuPDF)\n",
    "2. **OCR mit Tesseract** - Falls kein Text gefunden wurde\n",
    "3. **Vektorisierung des Grundrisses** - Format prüfen und ggf. vektorisieren\n",
    "4. **Textanalyse & Informationsextraktion** - NLP mit spaCy\n",
    "5. **Automatische Annotation** - Grundriss annotieren\n",
    "6. **Erweiterungen** - Zusammenfassung, Datenbankanbindung (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "\n",
    "Importiere alle benötigten Bibliotheken für den Workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Bibliotheken erfolgreich importiert!\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PDF processing\n",
    "from pdfminer.high_level import extract_text\n",
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Vector graphics\n",
    "import svgwrite\n",
    "\n",
    "# NLP\n",
    "import spacy\n",
    "\n",
    "# Set Tesseract path for Windows\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Display settings\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "print(\"Alle Bibliotheken erfolgreich importiert!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input Verification\n",
    "\n",
    "Überprüfe, ob die PDF bereits durchsuchbar ist und extrahiere Text mit pdfminer.six oder PyMuPDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versuche Textextraktion mit pdfminer.six...\n",
      "✓ Text erfolgreich extrahiert (3121 Zeichen)\n",
      "Verwendete Methode: pdfminer\n",
      "Extrahierter Text (erste 200 Zeichen): Sample PDF\n",
      "This is a simple PDF ﬁle. Fun fun fun.\n",
      "\n",
      "Lorem ipsum dolor  sit amet,  consectetuer  adipiscing elit.  Phasellus  facilisis odio  sed mi. \n",
      "Curabitur suscipit. Nullam vel nisi. Etiam semper i...\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path, method='auto'):\n",
    "    \"\"\"\n",
    "    Extrahiert Text aus einer PDF-Datei mit verschiedenen Methoden.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur PDF-Datei\n",
    "        method (str): 'auto', 'pdfminer', 'pymupdf' oder 'ocr'\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (extracted_text, method_used)\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"PDF-Datei nicht gefunden: {pdf_path}\")\n",
    "    \n",
    "    # Method 1: pdfminer.six\n",
    "    if method in ['auto', 'pdfminer']:\n",
    "        try:\n",
    "            print(\"Versuche Textextraktion mit pdfminer.six...\")\n",
    "            text = extract_text(pdf_path)\n",
    "            if text.strip():  # Check if meaningful text was extracted\n",
    "                print(f\"✓ Text erfolgreich extrahiert ({len(text)} Zeichen)\")\n",
    "                return text, 'pdfminer'\n",
    "            else:\n",
    "                print(\"⚠ Kein Text mit pdfminer gefunden\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ pdfminer Fehler: {e}\")\n",
    "    \n",
    "    # Method 2: PyMuPDF\n",
    "    if method in ['auto', 'pymupdf']:\n",
    "        try:\n",
    "            print(\"Versuche Textextraktion mit PyMuPDF...\")\n",
    "            doc = fitz.open(pdf_path)\n",
    "            text = \"\"\n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc[page_num]\n",
    "                text += page.get_text()\n",
    "            doc.close()\n",
    "            \n",
    "            if text.strip():\n",
    "                print(f\"✓ Text erfolgreich extrahiert ({len(text)} Zeichen)\")\n",
    "                return text, 'pymupdf'\n",
    "            else:\n",
    "                print(\"⚠ Kein Text mit PyMuPDF gefunden\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ PyMuPDF Fehler: {e}\")\n",
    "    \n",
    "    # Method 3: OCR fallback\n",
    "    if method in ['auto', 'ocr']:\n",
    "        print(\"Fallback: OCR wird verwendet...\")\n",
    "        return extract_text_with_ocr(pdf_path), 'ocr'\n",
    "    \n",
    "    return \"\", 'none'\n",
    "\n",
    "# Test der Funktion (mit Platzhalter)\n",
    "text, method = extract_text_from_pdf(\"example.pdf\")\n",
    "print(f\"Verwendete Methode: {method}\")\n",
    "print(f\"Extrahierter Text (erste 200 Zeichen): {text[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OCR mit Tesseract\n",
    "\n",
    "Konvertiere PDF-Seiten zu Bildern und extrahiere Text mit Tesseract OCR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_ocr(pdf_path, language='deu+eng'):\n",
    "    \"\"\"\n",
    "    Extrahiert Text aus PDF mit OCR (Tesseract).\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur PDF-Datei\n",
    "        language (str): Tesseract Sprachcode (deu=Deutsch, eng=Englisch)\n",
    "        \n",
    "    Returns:\n",
    "        str: Extrahierter Text\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Konvertiere PDF zu Bildern...\")\n",
    "        # PDF zu Bildern konvertieren\n",
    "        images = convert_from_path(pdf_path, dpi=300)  # Höhere DPI für bessere OCR\n",
    "        \n",
    "        extracted_text = \"\"\n",
    "        \n",
    "        print(f\"Verarbeite {len(images)} Seiten mit OCR...\")\n",
    "        for i, image in enumerate(images):\n",
    "            print(f\"  Seite {i+1}/{len(images)}\")\n",
    "            \n",
    "            # OCR auf jedes Bild anwenden\n",
    "            page_text = pytesseract.image_to_string(\n",
    "                image, \n",
    "                lang=language,\n",
    "                config='--psm 1'  # Page segmentation mode\n",
    "            )\n",
    "            \n",
    "            extracted_text += f\"\\n--- Seite {i+1} ---\\n{page_text}\\n\"\n",
    "        \n",
    "        print(f\"✓ OCR abgeschlossen ({len(extracted_text)} Zeichen extrahiert)\")\n",
    "        return extracted_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ OCR Fehler: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konvertiere PDF zu Bildern...\n",
      "Verarbeite 1 Seiten mit OCR...\n",
      "  Seite 1/1\n",
      "✓ OCR abgeschlossen (2872 Zeichen extrahiert)\n",
      "OCR Text (erste 200 Zeichen): \n",
      "--- Seite 1 ---\n",
      "sample PDF\n",
      "\n",
      "This ıs a simple PDF file. Fun fun fun.\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Phasellus facilisis odio sed mi.\n",
      "Curabitur suscipit. Nullam vel nisi. Et...\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image_for_ocr(image):\n",
    "    \"\"\"\n",
    "    Verbessert ein Bild für bessere OCR-Ergebnisse.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image oder numpy array\n",
    "        \n",
    "    Returns:\n",
    "        Processed image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Konvertiere zu numpy array falls nötig\n",
    "    if hasattr(image, 'mode'):\n",
    "        image = np.array(image)\n",
    "    \n",
    "    # Zu Graustufen konvertieren\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Rauschen reduzieren\n",
    "    denoised = cv2.medianBlur(gray, 3)\n",
    "    \n",
    "    # Kontrast verbessern\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "# Test der OCR-Funktion (mit Platzhalter)\n",
    "ocr_text = extract_text_with_ocr(\"example.pdf\")\n",
    "print(f\"OCR Text (erste 200 Zeichen): {ocr_text[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vektorisierung des Grundrisses\n",
    "\n",
    "Überprüfe das Dateiformat des Grundrisses und vektorisiere bei Bedarf mit OpenCV und Potrace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_format(file_path):\n",
    "    \"\"\"\n",
    "    Überprüft das Dateiformat einer Datei.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Pfad zur Datei\n",
    "        \n",
    "    Returns:\n",
    "        str: Dateiformat ('pdf', 'svg', 'dxf', 'image', 'unknown')\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Datei nicht gefunden: {file_path}\")\n",
    "    \n",
    "    # Get file extension\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    ext = ext.lower()\n",
    "    \n",
    "    format_mapping = {\n",
    "        '.pdf': 'pdf',\n",
    "        '.svg': 'svg',\n",
    "        '.dxf': 'dxf',\n",
    "        '.png': 'image',\n",
    "        '.jpg': 'image',\n",
    "        '.jpeg': 'image',\n",
    "        '.tiff': 'image',\n",
    "        '.tif': 'image',\n",
    "        '.bmp': 'image'\n",
    "    }\n",
    "    \n",
    "    return format_mapping.get(ext, 'unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_floorplan(file_path, output_dir=\"output\"):\n",
    "    \"\"\"\n",
    "    Vektorisiert einen Grundriss falls nötig.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Pfad zur Grundriss-Datei\n",
    "        output_dir (str): Ausgabeverzeichnis\n",
    "        \n",
    "    Returns:\n",
    "        str: Pfad zur vektorisierten SVG-Datei\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ausgabeverzeichnis erstellen\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Dateiformat überprüfen\n",
    "    file_format = check_file_format(file_path)\n",
    "    print(f\"Erkanntes Dateiformat: {file_format}\")\n",
    "    \n",
    "    # Base filename for output\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    svg_output_path = os.path.join(output_dir, f\"{base_name}_vectorized.svg\")\n",
    "    \n",
    "    # Bereits SVG?\n",
    "    if file_format == 'svg':\n",
    "        print(\"✓ Datei ist bereits im SVG-Format\")\n",
    "        return file_path\n",
    "    \n",
    "    # PDF mit Vektorpfaden?\n",
    "    elif file_format == 'pdf':\n",
    "        if check_pdf_for_vectors(file_path):\n",
    "            print(\"✓ PDF enthält Vektorpfade\")\n",
    "            # TODO: PDF Vektoren zu SVG konvertieren\n",
    "            # Für jetzt: Fallback zu Rasterbild-Vektorisierung\n",
    "            return vectorize_raster_to_svg(file_path, svg_output_path)\n",
    "        else:\n",
    "            print(\"⚠ PDF enthält keine Vektorpfade - verwende Rasterbild-Vektorisierung\")\n",
    "            return vectorize_raster_to_svg(file_path, svg_output_path)\n",
    "    \n",
    "    # Rasterbild\n",
    "    elif file_format == 'image':\n",
    "        print(\"ℹ Rasterbild erkannt - starte Vektorisierung\")\n",
    "        return vectorize_raster_to_svg(file_path, svg_output_path)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Nicht unterstütztes Dateiformat: {file_format}\")\n",
    "\n",
    "def check_pdf_for_vectors(pdf_path):\n",
    "    \"\"\"\n",
    "    Überprüft, ob eine PDF-Datei Vektorpfade enthält.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur PDF-Datei\n",
    "        \n",
    "    Returns:\n",
    "        bool: True wenn Vektorpfade gefunden wurden\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        for page_num in range(min(3, len(doc))):  # Nur erste 3 Seiten prüfen\n",
    "            page = doc[page_num]\n",
    "            paths = page.get_drawings()\n",
    "            if paths:\n",
    "                doc.close()\n",
    "                return True\n",
    "        doc.close()\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Überprüfen der PDF-Vektoren: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== HILFSFUNKTIONEN FÜR VERBESSERTE VEKTORISIERUNG =====\n",
    "\n",
    "def detect_text_regions(image):\n",
    "    \"\"\"\n",
    "    Erkennt Textbereiche im Bild um sie von der Linienvektorisierung auszuschließen.\n",
    "    \n",
    "    Args:\n",
    "        image: Original-Bild (farbig oder grau)\n",
    "        \n",
    "    Returns:\n",
    "        Binary mask der Textbereiche oder None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Zu Graustufen konvertieren\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # MSER (Maximally Stable Extremal Regions) für Text-Erkennung\n",
    "        mser = cv2.MSER_create(\n",
    "            _min_area=10,      # Mindestfläche\n",
    "            _max_area=5000,    # Maximale Fläche\n",
    "            _delta=3           # Empfindlichkeit\n",
    "        )\n",
    "        \n",
    "        regions, _ = mser.detectRegions(gray)\n",
    "        \n",
    "        # Maske erstellen\n",
    "        text_mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "        \n",
    "        for region in regions:\n",
    "            # Bounding Box der Region\n",
    "            x, y, w, h = cv2.boundingRect(region.reshape(-1, 1, 2))\n",
    "            \n",
    "            # Filter: Textähnliche Dimensionen\n",
    "            aspect_ratio = w / h if h > 0 else 0\n",
    "            if 0.1 < aspect_ratio < 10 and 5 < w < 200 and 5 < h < 50:\n",
    "                # Region als Text markieren\n",
    "                cv2.rectangle(text_mask, (x-2, y-2), (x+w+2, y+h+2), 255, -1)\n",
    "        \n",
    "        # Morphologische Operationen um Text-Regionen zu verbinden\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 2))\n",
    "        text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        return text_mask\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Text-Erkennung fehlgeschlagen: {e}\")\n",
    "        return None\n",
    "\n",
    "def detect_wall_regions(binary_image):\n",
    "    \"\"\"\n",
    "    Erkennt dicke schwarze Bereiche als Wände.\n",
    "    \n",
    "    Args:\n",
    "        binary_image: Binäres Eingabebild\n",
    "        \n",
    "    Returns:\n",
    "        Binary mask der Wandbereiche oder None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Morphologische Operationen um dicke Linien zu erkennen\n",
    "        # Horizontale Strukturen\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))\n",
    "        horizontal_walls = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        \n",
    "        # Vertikale Strukturen  \n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 15))\n",
    "        vertical_walls = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        \n",
    "        # Kombiniere horizontale und vertikale Wände\n",
    "        wall_regions = cv2.bitwise_or(horizontal_walls, vertical_walls)\n",
    "        \n",
    "        # Zusätzliche Filterung: Entferne sehr kleine Bereiche\n",
    "        contours, _ = cv2.findContours(wall_regions, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        filtered_walls = np.zeros_like(wall_regions)\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 100:  # Mindestfläche für Wände\n",
    "                cv2.fillPoly(filtered_walls, [contour], 255)\n",
    "        \n",
    "        return filtered_walls\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Wand-Erkennung fehlgeschlagen: {e}\")\n",
    "        return None\n",
    "\n",
    "def detect_and_merge_lines(image):\n",
    "    \"\"\"\n",
    "    Intelligente Linienerkennung mit Verschmelzung ähnlicher Linien.\n",
    "    \n",
    "    Args:\n",
    "        image: Bereinigtes binäres Bild\n",
    "        \n",
    "    Returns:\n",
    "        Liste verschmolzener Linien\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Hough-Linien erkennen mit strengeren Parametern\n",
    "        lines = cv2.HoughLinesP(\n",
    "            image, \n",
    "            rho=1, \n",
    "            theta=np.pi/180, \n",
    "            threshold=30,        # Höhere Schwelle\n",
    "            minLineLength=20,    # Mindestlänge\n",
    "            maxLineGap=5         # Kleinere Lücken\n",
    "        )\n",
    "        \n",
    "        if lines is None or len(lines) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Linien in einfacheres Format konvertieren\n",
    "        line_list = []\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            line_list.append((x1, y1, x2, y2))\n",
    "        \n",
    "        # Linien nach Ähnlichkeit gruppieren und verschmelzen\n",
    "        merged_lines = merge_similar_lines(line_list)\n",
    "        \n",
    "        print(f\"  Linien: {len(line_list)} → {len(merged_lines)} (nach Verschmelzung)\")\n",
    "        return merged_lines\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Linienerkennung fehlgeschlagen: {e}\")\n",
    "        return []\n",
    "\n",
    "def merge_similar_lines(lines, angle_threshold=5, distance_threshold=10):\n",
    "    \"\"\"\n",
    "    Verschmilzt ähnliche/kollineare Linien.\n",
    "    \n",
    "    Args:\n",
    "        lines: Liste von Linien (x1, y1, x2, y2)\n",
    "        angle_threshold: Winkel-Toleranz in Grad\n",
    "        distance_threshold: Abstand-Toleranz in Pixeln\n",
    "        \n",
    "    Returns:\n",
    "        Liste verschmolzener Linien\n",
    "    \"\"\"\n",
    "    if not lines:\n",
    "        return []\n",
    "    \n",
    "    merged = []\n",
    "    used = set()\n",
    "    \n",
    "    for i, line1 in enumerate(lines):\n",
    "        if i in used:\n",
    "            continue\n",
    "            \n",
    "        x1, y1, x2, y2 = line1\n",
    "        \n",
    "        # Suche ähnliche Linien\n",
    "        similar_lines = [line1]\n",
    "        used.add(i)\n",
    "        \n",
    "        for j, line2 in enumerate(lines):\n",
    "            if j in used or i == j:\n",
    "                continue\n",
    "                \n",
    "            if are_lines_similar(line1, line2, angle_threshold, distance_threshold):\n",
    "                similar_lines.append(line2)\n",
    "                used.add(j)\n",
    "        \n",
    "        # Verschmelze ähnliche Linien zu einer\n",
    "        if len(similar_lines) > 1:\n",
    "            merged_line = merge_line_group(similar_lines)\n",
    "            merged.append(merged_line)\n",
    "        else:\n",
    "            merged.append(line1)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def are_lines_similar(line1, line2, angle_threshold, distance_threshold):\n",
    "    \"\"\"\n",
    "    Überprüft ob zwei Linien ähnlich sind (ähnlicher Winkel und nahe beieinander).\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "    \n",
    "    # Winkel berechnen\n",
    "    angle1 = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "    angle2 = np.arctan2(y4 - y3, x4 - x3) * 180 / np.pi\n",
    "    \n",
    "    # Winkel-Differenz (berücksichtige 180°-Periodizität)\n",
    "    angle_diff = abs(angle1 - angle2)\n",
    "    angle_diff = min(angle_diff, 180 - angle_diff)\n",
    "    \n",
    "    if angle_diff > angle_threshold:\n",
    "        return False\n",
    "    \n",
    "    # Abstand zwischen Linien berechnen\n",
    "    # Vereinfacht: Abstand zwischen Mittelpunkten\n",
    "    mid1 = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "    mid2 = ((x3 + x4) / 2, (y3 + y4) / 2)\n",
    "    distance = np.sqrt((mid1[0] - mid2[0])**2 + (mid1[1] - mid2[1])**2)\n",
    "    \n",
    "    return distance < distance_threshold\n",
    "\n",
    "def merge_line_group(lines):\n",
    "    \"\"\"\n",
    "    Verschmilzt eine Gruppe ähnlicher Linien zu einer einzigen Linie.\n",
    "    \"\"\"\n",
    "    # Sammle alle Endpunkte\n",
    "    points = []\n",
    "    for x1, y1, x2, y2 in lines:\n",
    "        points.extend([(x1, y1), (x2, y2)])\n",
    "    \n",
    "    # Finde die beiden äußersten Punkte\n",
    "    points = np.array(points)\n",
    "    \n",
    "    # Hauptachse der Punkte finden (PCA)\n",
    "    mean_point = np.mean(points, axis=0)\n",
    "    centered_points = points - mean_point\n",
    "    \n",
    "    # SVD für Hauptrichtung\n",
    "    _, _, vh = np.linalg.svd(centered_points)\n",
    "    direction = vh[0]\n",
    "    \n",
    "    # Projiziere alle Punkte auf die Hauptachse\n",
    "    projections = np.dot(centered_points, direction)\n",
    "    \n",
    "    # Äußerste Projektionen finden\n",
    "    min_proj = np.min(projections)\n",
    "    max_proj = np.max(projections)\n",
    "    \n",
    "    # Zurück zu Koordinaten\n",
    "    start_point = mean_point + min_proj * direction\n",
    "    end_point = mean_point + max_proj * direction\n",
    "    \n",
    "    return (int(start_point[0]), int(start_point[1]), \n",
    "            int(end_point[0]), int(end_point[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SVG-ERSTELLUNGSFUNKTIONEN =====\n",
    "\n",
    "def add_wall_hatches(dwg, wall_regions, width, height):\n",
    "    \"\"\"\n",
    "    Fügt Wände als Schraffuren zum SVG hinzu.\n",
    "    \n",
    "    Args:\n",
    "        dwg: SVG Drawing Objekt\n",
    "        wall_regions: Binary mask der Wandbereiche\n",
    "        width, height: Bildabmessungen\n",
    "        \n",
    "    Returns:\n",
    "        Anzahl der hinzugefügten Wände\n",
    "    \"\"\"\n",
    "    if wall_regions is None:\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        # Schraffur-Pattern definieren\n",
    "        pattern_id = \"wallHatch\"\n",
    "        pattern = dwg.defs.add(dwg.pattern(\n",
    "            id=pattern_id,\n",
    "            patternUnits=\"userSpaceOnUse\",\n",
    "            size=(6, 6)\n",
    "        ))\n",
    "        \n",
    "        # Diagonale Linien für Schraffur\n",
    "        pattern.add(dwg.line(start=(0, 0), end=(6, 6), stroke=\"black\", stroke_width=\"0.5\"))\n",
    "        pattern.add(dwg.line(start=(0, 6), end=(6, 0), stroke=\"black\", stroke_width=\"0.5\"))\n",
    "        \n",
    "        # Wandkonturen finden\n",
    "        contours, _ = cv2.findContours(wall_regions, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        wall_count = 0\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 50:  # Nur größere Wände\n",
    "                # Kontur vereinfachen\n",
    "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "                \n",
    "                if len(approx) >= 3:\n",
    "                    # Path für SVG erstellen\n",
    "                    path_data = f\"M {approx[0][0][0]},{approx[0][0][1]}\"\n",
    "                    for point in approx[1:]:\n",
    "                        path_data += f\" L {point[0][0]},{point[0][1]}\"\n",
    "                    path_data += \" Z\"\n",
    "                    \n",
    "                    # Wand mit Schraffur hinzufügen\n",
    "                    dwg.add(dwg.path(d=path_data, \n",
    "                                   fill=f\"url(#{pattern_id})\",\n",
    "                                   stroke=\"black\", \n",
    "                                   stroke_width=\"2\"))\n",
    "                    wall_count += 1\n",
    "        \n",
    "        return wall_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Wand-Schraffuren fehlgeschlagen: {e}\")\n",
    "        return 0\n",
    "\n",
    "def add_lines_to_svg(dwg, lines):\n",
    "    \"\"\"\n",
    "    Fügt bereinigte Linien zum SVG hinzu.\n",
    "    \n",
    "    Args:\n",
    "        dwg: SVG Drawing Objekt\n",
    "        lines: Liste von Linien (x1, y1, x2, y2)\n",
    "        \n",
    "    Returns:\n",
    "        Anzahl der hinzugefügten Linien\n",
    "    \"\"\"\n",
    "    line_count = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line\n",
    "        \n",
    "        # Linenlänge prüfen\n",
    "        length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        if length > 10:  # Mindestlänge\n",
    "            dwg.add(dwg.line(\n",
    "                start=(int(x1), int(y1)), \n",
    "                end=(int(x2), int(y2)),\n",
    "                stroke=\"black\", \n",
    "                stroke_width=\"1\",\n",
    "                stroke_linecap=\"round\"\n",
    "            ))\n",
    "            line_count += 1\n",
    "    \n",
    "    return line_count\n",
    "\n",
    "def detect_important_contours(image, width, height):\n",
    "    \"\"\"\n",
    "    Erkennt wichtige Konturen ohne Überlappungen.\n",
    "    \n",
    "    Args:\n",
    "        image: Bereinigtes binäres Bild\n",
    "        width, height: Bildabmessungen\n",
    "        \n",
    "    Returns:\n",
    "        Liste wichtiger Konturen\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Konturen finden mit Hierarchie\n",
    "        contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        important_contours = []\n",
    "        min_area = (width * height) * 0.0001  # 0.01% der Gesamtfläche\n",
    "        max_area = (width * height) * 0.5     # 50% der Gesamtfläche\n",
    "        \n",
    "        for i, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            \n",
    "            # Filter nach Fläche\n",
    "            if not (min_area < area < max_area):\n",
    "                continue\n",
    "            \n",
    "            # Filter nach Seitenverhältnis (vermeidet sehr schmale Objekte)\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else float('inf')\n",
    "            if aspect_ratio > 20:  # Zu schmale Objekte ausschließen\n",
    "                continue\n",
    "            \n",
    "            # Filter nach Kompaktheit (vermeidet sehr verzweigte Formen)\n",
    "            if perimeter > 0:\n",
    "                compactness = 4 * np.pi * area / (perimeter * perimeter)\n",
    "                if compactness < 0.01:  # Zu verzweigte Formen ausschließen\n",
    "                    continue\n",
    "            \n",
    "            # Äußere Konturen bevorzugen (Hierarchie prüfen)\n",
    "            if hierarchy is not None:\n",
    "                parent = hierarchy[0][i][3]\n",
    "                if parent == -1 or len(important_contours) < 50:  # Äußere Konturen oder Limit\n",
    "                    important_contours.append(contour)\n",
    "            else:\n",
    "                important_contours.append(contour)\n",
    "        \n",
    "        return important_contours[:100]  # Maximal 100 Konturen\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Kontur-Erkennung fehlgeschlagen: {e}\")\n",
    "        return []\n",
    "\n",
    "def add_contours_to_svg(dwg, contours):\n",
    "    \"\"\"\n",
    "    Fügt wichtige Konturen zum SVG hinzu.\n",
    "    \n",
    "    Args:\n",
    "        dwg: SVG Drawing Objekt\n",
    "        contours: Liste von OpenCV Konturen\n",
    "        \n",
    "    Returns:\n",
    "        Anzahl der hinzugefügten Konturen\n",
    "    \"\"\"\n",
    "    contour_count = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Kontur vereinfachen\n",
    "        epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        \n",
    "        if len(approx) >= 3:\n",
    "            # Path erstellen\n",
    "            path_data = f\"M {approx[0][0][0]},{approx[0][0][1]}\"\n",
    "            for point in approx[1:]:\n",
    "                path_data += f\" L {point[0][0]},{point[0][1]}\"\n",
    "            path_data += \" Z\"\n",
    "            \n",
    "            dwg.add(dwg.path(d=path_data, \n",
    "                           fill=\"none\", \n",
    "                           stroke=\"gray\", \n",
    "                           stroke_width=\"0.5\",\n",
    "                           stroke_dasharray=\"2,2\"))\n",
    "            contour_count += 1\n",
    "    \n",
    "    return contour_count\n",
    "\n",
    "def add_text_to_svg(dwg, image, text_mask):\n",
    "    \"\"\"\n",
    "    Extrahiert Text mit OCR und fügt ihn als echten Text zum SVG hinzu.\n",
    "    \n",
    "    Args:\n",
    "        dwg: SVG Drawing Objekt\n",
    "        image: Original-Bild\n",
    "        text_mask: Maske der Textbereiche\n",
    "        \n",
    "    Returns:\n",
    "        Anzahl der hinzugefügten Texte\n",
    "    \"\"\"\n",
    "    if text_mask is None:\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        # Textbereiche finden\n",
    "        contours, _ = cv2.findContours(text_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        text_count = 0\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Bounding Box der Textregion\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Mindestgröße für Text\n",
    "            if w < 10 or h < 5:\n",
    "                continue\n",
    "            \n",
    "            # Textregion aus Bild ausschneiden\n",
    "            text_region = image[y:y+h, x:x+w]\n",
    "            \n",
    "            try:\n",
    "                # OCR auf die Textregion anwenden\n",
    "                text_content = pytesseract.image_to_string(\n",
    "                    text_region, \n",
    "                    lang='deu+eng',\n",
    "                    config='--psm 8 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzäöüÄÖÜß0123456789.,- '\n",
    "                ).strip()\n",
    "                \n",
    "                # Nur hinzufügen wenn sinnvoller Text erkannt wurde\n",
    "                if len(text_content) > 1 and any(c.isalnum() for c in text_content):\n",
    "                    # Schriftgröße basierend auf Texthöhe schätzen\n",
    "                    font_size = max(8, min(16, h * 0.7))\n",
    "                    \n",
    "                    # Text zum SVG hinzufügen\n",
    "                    dwg.add(dwg.text(\n",
    "                        text_content,\n",
    "                        insert=(x, y + h * 0.8),  # Baseline-korrigierte Position\n",
    "                        font_size=f\"{font_size}px\",\n",
    "                        font_family=\"Arial, sans-serif\",\n",
    "                        fill=\"blue\"\n",
    "                    ))\n",
    "                    text_count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # Einzelne OCR-Fehler ignorieren\n",
    "                continue\n",
    "        \n",
    "        return text_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Text-Extraktion fehlgeschlagen: {e}\")\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erkanntes Dateiformat: pdf\n",
      "⚠ PDF enthält keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Textbereiche...\n",
      "  Warnung: Text-Erkennung fehlgeschlagen: '_min_area' is an invalid keyword argument for MSER_create()\n",
      "Erkenne Wände...\n",
      "Erkenne und verschmelze Linien...\n",
      "  Linien: 815 → 387 (nach Verschmelzung)\n",
      "Erkenne wichtige Konturen...\n",
      "Extrahiere und füge Text hinzu...\n",
      "✓ Verbessertes SVG erstellt: output\\example_floorplan2_vectorized.svg\n",
      "  Wände: 107, Linien: 387, Konturen: 24, Texte: 0\n",
      "Vektorisierter Grundriss: output\\example_floorplan2_vectorized.svg\n"
     ]
    }
   ],
   "source": [
    "def vectorize_raster_to_svg(image_path, output_path):\n",
    "    \"\"\"\n",
    "    Verbesserte Konvertierung eines Rasterbilds zu SVG für Architekturpläne.\n",
    "    \n",
    "    Features:\n",
    "    - Text-Erkennung und -Erhaltung\n",
    "    - Intelligente Linienverschmelzung\n",
    "    - Wand-Schraffuren für dicke schwarze Bereiche\n",
    "    - Reduzierung überlappender Geometrien\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Pfad zum Eingabebild\n",
    "        output_path (str): Pfad für die Ausgabe-SVG\n",
    "        \n",
    "    Returns:\n",
    "        str: Pfad zur erstellten SVG-Datei\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Lade das Bild\n",
    "        if image_path.endswith('.pdf'):\n",
    "            images = convert_from_path(image_path, dpi=300)\n",
    "            image = np.array(images[0])\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(\"Bild konnte nicht geladen werden\")\n",
    "        \n",
    "        # Original für Text-Erkennung behalten\n",
    "        original_image = image.copy()\n",
    "        \n",
    "        # Bildverarbeitung für technische Zeichnungen\n",
    "        processed_image = preprocess_for_architectural_drawings(image)\n",
    "        height, width = processed_image.shape\n",
    "        \n",
    "        # 1. TEXT-ERKENNUNG UND -FILTER\n",
    "        print(\"Erkenne Textbereiche...\")\n",
    "        text_mask = detect_text_regions(original_image)\n",
    "        \n",
    "        # 2. WAND-ERKENNUNG (dicke schwarze Bereiche)\n",
    "        print(\"Erkenne Wände...\")\n",
    "        wall_regions = detect_wall_regions(processed_image)\n",
    "        \n",
    "        # 3. BEREINIGTES BILD FÜR LINIENERKENNUNG\n",
    "        # Entferne Text und Wände aus der Linienerkennung\n",
    "        lines_image = processed_image.copy()\n",
    "        if text_mask is not None:\n",
    "            lines_image = cv2.bitwise_and(lines_image, cv2.bitwise_not(text_mask))\n",
    "        if wall_regions is not None:\n",
    "            lines_image = cv2.bitwise_and(lines_image, cv2.bitwise_not(wall_regions))\n",
    "        \n",
    "        # SVG erstellen\n",
    "        dwg = svgwrite.Drawing(output_path, size=(f\"{width}px\", f\"{height}px\"))\n",
    "        \n",
    "        # 4. WÄNDE ALS SCHRAFFUREN HINZUFÜGEN\n",
    "        wall_count = add_wall_hatches(dwg, wall_regions, width, height)\n",
    "        \n",
    "        # 5. INTELLIGENTE LINIENERKENNUNG\n",
    "        print(\"Erkenne und verschmelze Linien...\")\n",
    "        cleaned_lines = detect_and_merge_lines(lines_image)\n",
    "        line_count = add_lines_to_svg(dwg, cleaned_lines)\n",
    "        \n",
    "        # 6. WICHTIGE KONTUREN (ohne Überlappungen)\n",
    "        print(\"Erkenne wichtige Konturen...\")\n",
    "        important_contours = detect_important_contours(lines_image, width, height)\n",
    "        contour_count = add_contours_to_svg(dwg, important_contours)\n",
    "        \n",
    "        # 7. TEXT HINZUFÜGEN\n",
    "        print(\"Extrahiere und füge Text hinzu...\")\n",
    "        text_count = add_text_to_svg(dwg, original_image, text_mask)\n",
    "        \n",
    "        # SVG speichern\n",
    "        dwg.save()\n",
    "        print(f\"✓ Verbessertes SVG erstellt: {output_path}\")\n",
    "        print(f\"  Wände: {wall_count}, Linien: {line_count}, Konturen: {contour_count}, Texte: {text_count}\")\n",
    "        return output_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Fehler bei der verbesserten Vektorisierung: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_for_architectural_drawings(image):\n",
    "    \"\"\"\n",
    "    Spezielle Bildvorverarbeitung für Architekturzeichnungen und technische Pläne.\n",
    "    \n",
    "    Args:\n",
    "        image: Eingabebild (numpy array)\n",
    "        \n",
    "    Returns:\n",
    "        Vorverarbeitetes binäres Bild\n",
    "    \"\"\"\n",
    "    \n",
    "    # Zu Graustufen konvertieren\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Kontrast verbessern\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Leichter Gaußscher Weichzeichner um Rauschen zu reduzieren\n",
    "    blurred = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
    "    \n",
    "    # Zwei verschiedene Schwellenwert-Methoden kombinieren\n",
    "    # 1. Adaptive Schwellenwert für lokale Variationen\n",
    "    adaptive = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # 2. Otsu-Schwellenwert für globale Binarisierung\n",
    "    _, otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Kombiniere beide Methoden\n",
    "    combined = cv2.bitwise_and(adaptive, otsu)\n",
    "    \n",
    "    # Morphologische Operationen um Linien zu verbessern\n",
    "    # Kleiner Kernel für feine Details\n",
    "    kernel_small = np.ones((2,2), np.uint8)\n",
    "    # Größerer Kernel für Linien\n",
    "    kernel_line = cv2.getStructuringElement(cv2.MORPH_RECT, (3,1))\n",
    "    \n",
    "    # Schließe kleine Lücken in Linien\n",
    "    closed = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel_small)\n",
    "    \n",
    "    # Entferne kleine Artefakte\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_small)\n",
    "    \n",
    "    # Invertiere falls nötig (schwarze Linien auf weißem Hintergrund)\n",
    "    # Überprüfe welche Farbe mehr Pixel hat\n",
    "    if np.sum(opened == 0) < np.sum(opened == 255):\n",
    "        opened = cv2.bitwise_not(opened)\n",
    "    \n",
    "    return opened\n",
    "\n",
    "# Test der Vektorisierungsfunktion (mit Platzhalter)\n",
    "svg_path = vectorize_floorplan(\"example_floorplan2.pdf\")\n",
    "print(f\"Vektorisierter Grundriss: {svg_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 === TEST DER VERBESSERTEN VEKTORISIERUNG ===\n",
      "\n",
      "📄 Teste mit: example_floorplan.pdf\n",
      "--------------------------------------------------\n",
      "Erkanntes Dateiformat: pdf\n",
      "⚠ PDF enthält keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Textbereiche...\n",
      "  Warnung: Text-Erkennung fehlgeschlagen: '_min_area' is an invalid keyword argument for MSER_create()\n",
      "Erkenne Wände...\n",
      "Erkenne und verschmelze Linien...\n",
      "  Linien: 104 → 52 (nach Verschmelzung)\n",
      "Erkenne wichtige Konturen...\n",
      "Extrahiere und füge Text hinzu...\n",
      "✓ Verbessertes SVG erstellt: output_improved\\example_floorplan_vectorized.svg\n",
      "  Wände: 30, Linien: 52, Konturen: 0, Texte: 0\n",
      "✅ Verbessertes SVG erstellt: output_improved\\example_floorplan_vectorized.svg\n",
      "📊 Dateigröße: 10.4 KB\n",
      "\n",
      "📄 Teste mit: example_floorplan2.pdf\n",
      "--------------------------------------------------\n",
      "Erkanntes Dateiformat: pdf\n",
      "⚠ PDF enthält keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Textbereiche...\n",
      "  Warnung: Text-Erkennung fehlgeschlagen: '_min_area' is an invalid keyword argument for MSER_create()\n",
      "Erkenne Wände...\n",
      "Erkenne und verschmelze Linien...\n",
      "  Linien: 815 → 387 (nach Verschmelzung)\n",
      "Erkenne wichtige Konturen...\n",
      "Extrahiere und füge Text hinzu...\n",
      "✓ Verbessertes SVG erstellt: output_improved\\example_floorplan2_vectorized.svg\n",
      "  Wände: 107, Linien: 387, Konturen: 24, Texte: 0\n",
      "✅ Verbessertes SVG erstellt: output_improved\\example_floorplan2_vectorized.svg\n",
      "📊 Dateigröße: 59.7 KB\n",
      "\n",
      "💡 VERBESSERUNGEN:\n",
      "✓ Text-Erkennung verhindert Übervektorisierung von Beschriftungen\n",
      "✓ Wände werden als Schraffuren dargestellt\n",
      "✓ Intelligente Linienverschmelzung reduziert Überlappungen\n",
      "✓ Wichtige Konturen werden gefiltert\n",
      "✓ OCR-extrahierter Text wird als echte SVG-Texte eingefügt\n",
      "\n",
      "🎯 NÄCHSTE SCHRITTE:\n",
      "• Parameter für spezifische Grundriss-Typen anpassen\n",
      "• Fein-Tuning der Filter-Schwellenwerte\n",
      "• Integration von Architektur-spezifischen Symbolen\n",
      "• Export-Optionen für CAD-Software\n"
     ]
    }
   ],
   "source": [
    "# ===== TEST DER VERBESSERTEN VEKTORISIERUNG =====\n",
    "\n",
    "print(\"🚀 === TEST DER VERBESSERTEN VEKTORISIERUNG ===\")\n",
    "print()\n",
    "\n",
    "# Test mit verfügbarem Grundriss\n",
    "test_files = [\"example_floorplan.pdf\", \"example_floorplan2.pdf\"]\n",
    "\n",
    "for test_file in test_files:\n",
    "    if os.path.exists(test_file):\n",
    "        print(f\"📄 Teste mit: {test_file}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Verbesserte Vektorisierung ausführen\n",
    "            svg_path = vectorize_floorplan(test_file, \"output_improved\")\n",
    "            \n",
    "            if svg_path:\n",
    "                print(f\"✅ Verbessertes SVG erstellt: {svg_path}\")\n",
    "                \n",
    "                # Dateigröße prüfen\n",
    "                if os.path.exists(svg_path):\n",
    "                    file_size = os.path.getsize(svg_path) / 1024  # KB\n",
    "                    print(f\"📊 Dateigröße: {file_size:.1f} KB\")\n",
    "                \n",
    "            else:\n",
    "                print(\"❌ Vektorisierung fehlgeschlagen\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Fehler: {e}\")\n",
    "        \n",
    "        print()\n",
    "    else:\n",
    "        print(f\"⚠️ Datei nicht gefunden: {test_file}\")\n",
    "\n",
    "print(\"💡 VERBESSERUNGEN:\")\n",
    "print(\"✓ Text-Erkennung verhindert Übervektorisierung von Beschriftungen\")\n",
    "print(\"✓ Wände werden als Schraffuren dargestellt\")  \n",
    "print(\"✓ Intelligente Linienverschmelzung reduziert Überlappungen\")\n",
    "print(\"✓ Wichtige Konturen werden gefiltert\")\n",
    "print(\"✓ OCR-extrahierter Text wird als echte SVG-Texte eingefügt\")\n",
    "print()\n",
    "print(\"🎯 NÄCHSTE SCHRITTE:\")\n",
    "print(\"• Parameter für spezifische Grundriss-Typen anpassen\")\n",
    "print(\"• Fein-Tuning der Filter-Schwellenwerte\") \n",
    "print(\"• Integration von Architektur-spezifischen Symbolen\")\n",
    "print(\"• Export-Optionen für CAD-Software\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== HILFSFUNKTION FÜR PDF-ANALYSE =====\n",
    "\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    \"\"\"\n",
    "    Überprüft, ob eine PDF-Datei durchsuchbar ist (Text enthält).\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur PDF-Datei\n",
    "        \n",
    "    Returns:\n",
    "        bool: True wenn durchsuchbar, False wenn nur Bilder\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Methode 1: pdfminer versuchen\n",
    "        text = extract_text(pdf_path)\n",
    "        if text and len(text.strip()) > 10:  # Mindestens 10 Zeichen sinnvoller Text\n",
    "            print(f\"📄 PDF-Status: Durchsuchbar\")\n",
    "            print(f\"📝 Gefundener Text: {len(text)} Zeichen\")\n",
    "            return True\n",
    "        \n",
    "        # Methode 2: PyMuPDF versuchen\n",
    "        doc = fitz.open(pdf_path)\n",
    "        total_text = \"\"\n",
    "        for page_num in range(min(3, len(doc))):  # Erste 3 Seiten prüfen\n",
    "            page = doc[page_num]\n",
    "            page_text = page.get_text()\n",
    "            total_text += page_text\n",
    "        doc.close()\n",
    "        \n",
    "        if len(total_text.strip()) > 10:\n",
    "            print(f\"📄 PDF-Status: Durchsuchbar\")\n",
    "            print(f\"📝 Gefundener Text: {len(total_text)} Zeichen\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"📄 PDF-Status: Nicht durchsuchbar (Raster-PDF)\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Fehler beim Überprüfen der PDF: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test der korrigierten Vektorisierung ===\n",
      "Erkanntes Dateiformat: pdf\n",
      "⚠ PDF enthält keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Konturen...\n",
      "Erkenne gerade Linien...\n",
      "Erkenne Kreise...\n",
      "✓ SVG erstellt: output\\example_floorplan_vectorized.svg\n",
      "  Konturen: 1987, Linien: 8999, Kreise: 312\n",
      "✅ Vektorisierung erfolgreich: output\\example_floorplan_vectorized.svg\n"
     ]
    }
   ],
   "source": [
    "# Test mit der korrigierten Vektorisierung\n",
    "print(\"=== Test der korrigierten Vektorisierung ===\")\n",
    "try:\n",
    "    svg_path = vectorize_floorplan(\"example_floorplan.pdf\")\n",
    "    if svg_path:\n",
    "        print(f\"✅ Vektorisierung erfolgreich: {svg_path}\")\n",
    "    else:\n",
    "        print(\"❌ Vektorisierung fehlgeschlagen\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Unerwarteter Fehler: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test der verbesserten Vektorisierung ===\n",
      "Erkanntes Dateiformat: pdf\n",
      "⚠ PDF enthält keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Konturen...\n",
      "Erkenne gerade Linien...\n",
      "Erkenne Kreise...\n"
     ]
    }
   ],
   "source": [
    "# Zusätzliche Hilfsfunktion für bessere Visualisierung und Debugging\n",
    "def save_debug_images(image, processed_image, output_dir=\"debug\"):\n",
    "    \"\"\"\n",
    "    Speichert Debug-Bilder um die Bildverarbeitung zu visualisieren.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Original speichern\n",
    "    if len(image.shape) == 3:\n",
    "        cv2.imwrite(os.path.join(output_dir, \"01_original.png\"), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    else:\n",
    "        cv2.imwrite(os.path.join(output_dir, \"01_original.png\"), image)\n",
    "    \n",
    "    # Verarbeitetes Bild speichern\n",
    "    cv2.imwrite(os.path.join(output_dir, \"02_processed.png\"), processed_image)\n",
    "    \n",
    "    print(f\"Debug-Bilder gespeichert in: {output_dir}\")\n",
    "\n",
    "# Test mit verbesserter Vektorisierung\n",
    "print(\"=== Test der verbesserten Vektorisierung ===\")\n",
    "svg_path = vectorize_floorplan(\"example_floorplan2.pdf\")\n",
    "print(f\"Vektorisierter Grundriss: {svg_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Textanalyse & Informationsextraktion\n",
    "\n",
    "Verwende NLP (spaCy) um relevante Schlüsselwörter, Positionen, Materialien und Aufgaben zu extrahieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_construction_information(text):\n",
    "    \"\"\"\n",
    "    Extrahiert relevante Bauinformationen aus Text mit spaCy NLP.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Eingabetext aus PDF/OCR\n",
    "        \n",
    "    Returns:\n",
    "        dict: Strukturierte Informationen (Materialien, Räume, Maße, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Lade deutsches spaCy-Modell\n",
    "        nlp = spacy.load('de_core_news_lg')\n",
    "        \n",
    "        # Text verarbeiten\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # Initialisiere Ergebnis-Dictionary\n",
    "        extracted_info = {\n",
    "            'materials': [],\n",
    "            'rooms': [],\n",
    "            'measurements': [],\n",
    "            'positions': [],\n",
    "            'tasks': [],\n",
    "            'entities': [],\n",
    "            'keywords': []\n",
    "        }\n",
    "        \n",
    "        # 1. Benannte Entitäten extrahieren\n",
    "        for ent in doc.ents:\n",
    "            extracted_info['entities'].append({\n",
    "                'text': ent.text,\n",
    "                'label': ent.label_,\n",
    "                'description': spacy.explain(ent.label_)\n",
    "            })\n",
    "        \n",
    "        # 2. Baumaterialien finden (einfache Keyword-Liste)\n",
    "        material_keywords = [\n",
    "            'beton', 'stahlbeton', 'ziegel', 'mauerwerk', 'holz', 'stahl',\n",
    "            'glas', 'aluminium', 'kunststoff', 'dämm', 'isolier', 'putz',\n",
    "            'fliesen', 'parkett', 'laminat', 'estrich', 'fundament'\n",
    "        ]\n",
    "        \n",
    "        for token in doc:\n",
    "            if any(keyword in token.text.lower() for keyword in material_keywords):\n",
    "                extracted_info['materials'].append({\n",
    "                    'text': token.text,\n",
    "                    'context': token.sent.text[:100] + \"...\" if len(token.sent.text) > 100 else token.sent.text\n",
    "                })\n",
    "        \n",
    "        # 3. Räume und Bereiche finden\n",
    "        room_keywords = [\n",
    "            'raum', 'zimmer', 'küche', 'bad', 'wohnzimmer', 'schlafzimmer',\n",
    "            'flur', 'diele', 'keller', 'dachboden', 'garage', 'balkon',\n",
    "            'terrasse', 'büro', 'arbeitszimmer', 'gäste'\n",
    "        ]\n",
    "        \n",
    "        for token in doc:\n",
    "            if any(keyword in token.text.lower() for keyword in room_keywords):\n",
    "                extracted_info['rooms'].append({\n",
    "                    'text': token.text,\n",
    "                    'context': token.sent.text[:100] + \"...\" if len(token.sent.text) > 100 else token.sent.text\n",
    "                })\n",
    "        \n",
    "        # 4. Maße und Dimensionen finden (einfacher Regex-Ansatz)\n",
    "        import re\n",
    "        measurement_patterns = [\n",
    "            r'\\d+[,.]?\\d*\\s*[x×]\\s*\\d+[,.]?\\d*\\s*m',  # \"3,5 x 4,2 m\"\n",
    "            r'\\d+[,.]?\\d*\\s*m²',                        # \"25,3 m²\"\n",
    "            r'\\d+[,.]?\\d*\\s*cm',                        # \"120 cm\"\n",
    "            r'\\d+[,.]?\\d*\\s*mm',                        # \"800 mm\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in measurement_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                extracted_info['measurements'].append(match)\n",
    "        \n",
    "        # 5. Positionen und Lage-Angaben\n",
    "        position_keywords = [\n",
    "            'nord', 'süd', 'ost', 'west', 'links', 'rechts', 'oben', 'unten',\n",
    "            'erdgeschoss', 'obergeschoss', 'untergeschoss', 'dachgeschoss'\n",
    "        ]\n",
    "        \n",
    "        for token in doc:\n",
    "            if any(keyword in token.text.lower() for keyword in position_keywords):\n",
    "                extracted_info['positions'].append({\n",
    "                    'text': token.text,\n",
    "                    'context': token.sent.text[:100] + \"...\" if len(token.sent.text) > 100 else token.sent.text\n",
    "                })\n",
    "        \n",
    "        print(f\"✓ NLP-Analyse abgeschlossen:\")\n",
    "        print(f\"  Entitäten: {len(extracted_info['entities'])}\")\n",
    "        print(f\"  Materialien: {len(extracted_info['materials'])}\")\n",
    "        print(f\"  Räume: {len(extracted_info['rooms'])}\")\n",
    "        print(f\"  Maße: {len(extracted_info['measurements'])}\")\n",
    "        print(f\"  Positionen: {len(extracted_info['positions'])}\")\n",
    "        \n",
    "        return extracted_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Fehler bei der NLP-Analyse: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test der NLP-Informationsextraktion ===\n",
      "✓ NLP-Analyse abgeschlossen:\n",
      "  Entitäten: 99\n",
      "  Materialien: 0\n",
      "  Räume: 0\n",
      "  Maße: 0\n",
      "  Positionen: 0\n",
      "\n",
      "ENTITIES:\n",
      "                            Text   Typ  \\\n",
      "0   Sample PDF\\nThis is a simple  MISC   \n",
      "1                    Fun fun fun  MISC   \n",
      "2  consectetuer  adipiscing elit  MISC   \n",
      "3                       suscipit   PER   \n",
      "4                         Nullam   PER   \n",
      "\n",
      "                                        Beschreibung Kategorie  \n",
      "0  Miscellaneous entities, e.g. events, nationali...   Entität  \n",
      "1  Miscellaneous entities, e.g. events, nationali...   Entität  \n",
      "2  Miscellaneous entities, e.g. events, nationali...   Entität  \n",
      "3                            Named person or family.   Entität  \n",
      "4                            Named person or family.   Entität  \n"
     ]
    }
   ],
   "source": [
    "def create_structured_dataframe(extracted_info):\n",
    "    \"\"\"\n",
    "    Konvertiert extrahierte Informationen in strukturierte pandas DataFrames.\n",
    "    \n",
    "    Args:\n",
    "        extracted_info (dict): Ergebnis von extract_construction_information()\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary mit DataFrames für verschiedene Kategorien\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframes = {}\n",
    "    \n",
    "    # Materials DataFrame\n",
    "    if extracted_info.get('materials'):\n",
    "        materials_data = []\n",
    "        for item in extracted_info['materials']:\n",
    "            materials_data.append({\n",
    "                'Material': item['text'],\n",
    "                'Kontext': item['context'],\n",
    "                'Kategorie': 'Material'\n",
    "            })\n",
    "        dataframes['materials'] = pd.DataFrame(materials_data)\n",
    "    \n",
    "    # Rooms DataFrame\n",
    "    if extracted_info.get('rooms'):\n",
    "        rooms_data = []\n",
    "        for item in extracted_info['rooms']:\n",
    "            rooms_data.append({\n",
    "                'Raum': item['text'],\n",
    "                'Kontext': item['context'],\n",
    "                'Kategorie': 'Raum'\n",
    "            })\n",
    "        dataframes['rooms'] = pd.DataFrame(rooms_data)\n",
    "    \n",
    "    # Measurements DataFrame\n",
    "    if extracted_info.get('measurements'):\n",
    "        measurements_data = []\n",
    "        for measurement in extracted_info['measurements']:\n",
    "            measurements_data.append({\n",
    "                'Maß': measurement,\n",
    "                'Kategorie': 'Abmessung'\n",
    "            })\n",
    "        dataframes['measurements'] = pd.DataFrame(measurements_data)\n",
    "    \n",
    "    # Entities DataFrame\n",
    "    if extracted_info.get('entities'):\n",
    "        entities_data = []\n",
    "        for entity in extracted_info['entities']:\n",
    "            entities_data.append({\n",
    "                'Text': entity['text'],\n",
    "                'Typ': entity['label'],\n",
    "                'Beschreibung': entity['description'],\n",
    "                'Kategorie': 'Entität'\n",
    "            })\n",
    "        dataframes['entities'] = pd.DataFrame(entities_data)\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Test der NLP-Funktionen mit dem bereits extrahierten Text\n",
    "print(\"=== Test der NLP-Informationsextraktion ===\")\n",
    "if 'text' in locals():\n",
    "    extracted_info = extract_construction_information(text)\n",
    "    dataframes = create_structured_dataframe(extracted_info)\n",
    "    \n",
    "    # Zeige Ergebnisse\n",
    "    for category, df in dataframes.items():\n",
    "        if not df.empty:\n",
    "            print(f\"\\n{category.upper()}:\")\n",
    "            print(df.head())\n",
    "else:\n",
    "    print(\"Verwende Beispieltext für Demo...\")\n",
    "    example_text = \"\"\"\n",
    "    Die Wände des Gebäudes werden in Stahlbeton ausgeführt. \n",
    "    Das Wohnzimmer hat eine Größe von 25,3 m². \n",
    "    Die Küche wird mit Fliesen ausgestattet.\n",
    "    Im Erdgeschoss befinden sich 3 Räume.\n",
    "    \"\"\"\n",
    "    extracted_info = extract_construction_information(example_text)\n",
    "    dataframes = create_structured_dataframe(extracted_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Automatische Annotation des Grundrisses\n",
    "\n",
    "Lade den vektorisierten Grundriss und platziere automatisch generierte Annotationen basierend auf den extrahierten Informationen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_floorplan_with_info(svg_path, extracted_info, output_path=None):\n",
    "    \"\"\"\n",
    "    Fügt Annotationen zum SVG-Grundriss basierend auf extrahierten Informationen hinzu.\n",
    "    \n",
    "    Args:\n",
    "        svg_path (str): Pfad zum vektorisierten SVG-Grundriss\n",
    "        extracted_info (dict): Extrahierte Informationen aus NLP\n",
    "        output_path (str): Ausgabepfad für annotierte SVG (optional)\n",
    "        \n",
    "    Returns:\n",
    "        str: Pfad zur annotierten SVG-Datei\n",
    "    \"\"\"\n",
    "    \n",
    "    if not svg_path or not os.path.exists(svg_path):\n",
    "        print(\"❌ SVG-Grundriss nicht gefunden\")\n",
    "        return None\n",
    "    \n",
    "    # Ausgabepfad bestimmen\n",
    "    if not output_path:\n",
    "        base_name = os.path.splitext(svg_path)[0]\n",
    "        output_path = f\"{base_name}_annotated.svg\"\n",
    "    \n",
    "    try:\n",
    "        # SVG-Dimensionen aus der ursprünglichen Datei lesen\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(svg_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Versuche Dimensionen zu extrahieren\n",
    "        width = 800  # Fallback-Werte\n",
    "        height = 600\n",
    "        \n",
    "        if 'viewBox' in root.attrib:\n",
    "            viewbox = root.attrib['viewBox'].split()\n",
    "            width, height = int(float(viewbox[2])), int(float(viewbox[3]))\n",
    "        elif 'width' in root.attrib and 'height' in root.attrib:\n",
    "            width = int(float(root.attrib['width'].replace('px', '')))\n",
    "            height = int(float(root.attrib['height'].replace('px', '')))\n",
    "        \n",
    "        # Neue SVG mit Annotationen erstellen\n",
    "        dwg = svgwrite.Drawing(output_path, size=(f\"{width}px\", f\"{height}px\"))\n",
    "        \n",
    "        # Lade das ursprüngliche SVG als Hintergrund\n",
    "        # (Vereinfacht: kopiere nur die Grundriss-Geometrie)\n",
    "        \n",
    "        # Annotation-Bereiche definieren\n",
    "        annotation_areas = {\n",
    "            'materials': {'x': 20, 'y': 30, 'color': 'blue'},\n",
    "            'rooms': {'x': 20, 'y': height//2, 'color': 'green'},\n",
    "            'measurements': {'x': width-200, 'y': 30, 'color': 'red'},\n",
    "            'general': {'x': width-200, 'y': height//2, 'color': 'purple'}\n",
    "        }\n",
    "        \n",
    "        # Titel hinzufügen\n",
    "        dwg.add(dwg.text(\"Automatisch annotierter Grundriss\", \n",
    "                        insert=(width//2, 20), \n",
    "                        text_anchor=\"middle\", \n",
    "                        font_size=\"16px\", \n",
    "                        font_weight=\"bold\"))\n",
    "        \n",
    "        # Materialien annotieren\n",
    "        if extracted_info.get('materials'):\n",
    "            y_pos = annotation_areas['materials']['y']\n",
    "            dwg.add(dwg.text(\"Materialien:\", \n",
    "                           insert=(annotation_areas['materials']['x'], y_pos), \n",
    "                           font_size=\"14px\", \n",
    "                           font_weight=\"bold\", \n",
    "                           fill=annotation_areas['materials']['color']))\n",
    "            \n",
    "            for i, material in enumerate(extracted_info['materials'][:5]):  # Max 5 Einträge\n",
    "                y_pos += 20\n",
    "                dwg.add(dwg.text(f\"• {material['text']}\", \n",
    "                               insert=(annotation_areas['materials']['x'] + 10, y_pos), \n",
    "                               font_size=\"12px\", \n",
    "                               fill=annotation_areas['materials']['color']))\n",
    "        \n",
    "        # Räume annotieren\n",
    "        if extracted_info.get('rooms'):\n",
    "            y_pos = annotation_areas['rooms']['y']\n",
    "            dwg.add(dwg.text(\"Räume:\", \n",
    "                           insert=(annotation_areas['rooms']['x'], y_pos), \n",
    "                           font_size=\"14px\", \n",
    "                           font_weight=\"bold\", \n",
    "                           fill=annotation_areas['rooms']['color']))\n",
    "            \n",
    "            for i, room in enumerate(extracted_info['rooms'][:5]):  # Max 5 Einträge\n",
    "                y_pos += 20\n",
    "                dwg.add(dwg.text(f\"• {room['text']}\", \n",
    "                               insert=(annotation_areas['rooms']['x'] + 10, y_pos), \n",
    "                               font_size=\"12px\", \n",
    "                               fill=annotation_areas['rooms']['color']))\n",
    "        \n",
    "        # Maße annotieren\n",
    "        if extracted_info.get('measurements'):\n",
    "            y_pos = annotation_areas['measurements']['y']\n",
    "            dwg.add(dwg.text(\"Abmessungen:\", \n",
    "                           insert=(annotation_areas['measurements']['x'], y_pos), \n",
    "                           font_size=\"14px\", \n",
    "                           font_weight=\"bold\", \n",
    "                           fill=annotation_areas['measurements']['color']))\n",
    "            \n",
    "            for i, measurement in enumerate(extracted_info['measurements'][:5]):  # Max 5 Einträge\n",
    "                y_pos += 20\n",
    "                dwg.add(dwg.text(f\"• {measurement}\", \n",
    "                               insert=(annotation_areas['measurements']['x'] + 10, y_pos), \n",
    "                               font_size=\"12px\", \n",
    "                               fill=annotation_areas['measurements']['color']))\n",
    "        \n",
    "        # Legende hinzufügen\n",
    "        legend_y = height - 100\n",
    "        dwg.add(dwg.text(\"Legende:\", \n",
    "                       insert=(20, legend_y), \n",
    "                       font_size=\"14px\", \n",
    "                       font_weight=\"bold\"))\n",
    "        \n",
    "        legend_items = [\n",
    "            (\"Materialien\", annotation_areas['materials']['color']),\n",
    "            (\"Räume\", annotation_areas['rooms']['color']),\n",
    "            (\"Abmessungen\", annotation_areas['measurements']['color'])\n",
    "        ]\n",
    "        \n",
    "        for i, (label, color) in enumerate(legend_items):\n",
    "            y = legend_y + 20 + (i * 20)\n",
    "            dwg.add(dwg.circle(center=(30, y-5), r=5, fill=color))\n",
    "            dwg.add(dwg.text(label, insert=(45, y), font_size=\"12px\"))\n",
    "        \n",
    "        # SVG speichern\n",
    "        dwg.save()\n",
    "        print(f\"✓ Annotierter Grundriss erstellt: {output_path}\")\n",
    "        return output_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Fehler bei der Annotation: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Kompletter Workflow\n",
    "\n",
    "Zusammenführung aller Schritte in einer einzigen Workflow-Funktion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_construction_documents(pdf_path, floorplan_path, output_dir=\"workflow_output\"):\n",
    "    \"\"\"\n",
    "    Kompletter automatisierter Workflow für Bauausschreibungen und Grundrisse.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur Bauausschreibungs-PDF\n",
    "        floorplan_path (str): Pfad zum Grundriss (PDF/Bild)\n",
    "        output_dir (str): Ausgabeverzeichnis\n",
    "        \n",
    "    Returns:\n",
    "        dict: Ergebnisse des gesamten Workflows\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ausgabeverzeichnis erstellen\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"🏗️ === AUTOMATISIERTER BAU-WORKFLOW GESTARTET ===\")\n",
    "    print(f\"📄 PDF: {pdf_path}\")\n",
    "    print(f\"🏠 Grundriss: {floorplan_path}\")\n",
    "    print(f\"📁 Ausgabe: {output_dir}\")\n",
    "    print()\n",
    "    \n",
    "    workflow_results = {\n",
    "        'success': False,\n",
    "        'text_extraction': None,\n",
    "        'method_used': None,\n",
    "        'svg_path': None,\n",
    "        'extracted_info': None,\n",
    "        'annotated_svg': None,\n",
    "        'dataframes': None,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Schritt 1: Text aus PDF extrahieren\n",
    "        print(\"🔍 Schritt 1: Text-Extraktion...\")\n",
    "        text, method = extract_text_from_pdf(pdf_path)\n",
    "        \n",
    "        if not text.strip():\n",
    "            workflow_results['errors'].append(\"Keine Textextraktion möglich\")\n",
    "            print(\"❌ Keine Textextraktion möglich\")\n",
    "            return workflow_results\n",
    "        \n",
    "        workflow_results['text_extraction'] = text\n",
    "        workflow_results['method_used'] = method\n",
    "        print(f\"✅ Text extrahiert mit Methode: {method}\")\n",
    "        print()\n",
    "        \n",
    "        # Schritt 2: Grundriss vektorisieren\n",
    "        print(\"🎨 Schritt 2: Grundriss-Vektorisierung...\")\n",
    "        svg_path = vectorize_floorplan(floorplan_path, output_dir)\n",
    "        \n",
    "        if not svg_path:\n",
    "            workflow_results['errors'].append(\"Vektorisierung fehlgeschlagen\")\n",
    "            print(\"❌ Vektorisierung fehlgeschlagen\")\n",
    "        else:\n",
    "            workflow_results['svg_path'] = svg_path\n",
    "            print(f\"✅ Grundriss vektorisiert: {svg_path}\")\n",
    "        print()\n",
    "        \n",
    "        # Schritt 3: NLP-Informationsextraktion\n",
    "        print(\"🧠 Schritt 3: NLP-Analyse...\")\n",
    "        extracted_info = extract_construction_information(text)\n",
    "        \n",
    "        if not extracted_info:\n",
    "            workflow_results['errors'].append(\"NLP-Analyse fehlgeschlagen\")\n",
    "            print(\"❌ NLP-Analyse fehlgeschlagen\")\n",
    "        else:\n",
    "            workflow_results['extracted_info'] = extracted_info\n",
    "            # Strukturiere Daten in DataFrames\n",
    "            dataframes = create_structured_dataframe(extracted_info)\n",
    "            workflow_results['dataframes'] = dataframes\n",
    "            print(\"✅ NLP-Analyse abgeschlossen\")\n",
    "        print()\n",
    "        \n",
    "        # Schritt 4: Automatische Annotation\n",
    "        if svg_path and extracted_info:\n",
    "            print(\"📝 Schritt 4: Automatische Annotation...\")\n",
    "            annotated_svg = annotate_floorplan_with_info(svg_path, extracted_info, \n",
    "                                                       os.path.join(output_dir, \"annotated_floorplan.svg\"))\n",
    "            \n",
    "            if annotated_svg:\n",
    "                workflow_results['annotated_svg'] = annotated_svg\n",
    "                print(f\"✅ Annotation erstellt: {annotated_svg}\")\n",
    "            else:\n",
    "                workflow_results['errors'].append(\"Annotation fehlgeschlagen\")\n",
    "                print(\"❌ Annotation fehlgeschlagen\")\n",
    "        else:\n",
    "            print(\"⚠️ Schritt 4 übersprungen (Vektorisierung oder NLP fehlgeschlagen)\")\n",
    "        print()\n",
    "        \n",
    "        # Schritt 5: Ergebnisse speichern\n",
    "        print(\"💾 Schritt 5: Ergebnisse speichern...\")\n",
    "        \n",
    "        # Extrahierten Text speichern\n",
    "        with open(os.path.join(output_dir, \"extracted_text.txt\"), 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "        \n",
    "        # DataFrames als CSV speichern\n",
    "        if workflow_results.get('dataframes'):\n",
    "            for category, df in workflow_results['dataframes'].items():\n",
    "                if not df.empty:\n",
    "                    df.to_csv(os.path.join(output_dir, f\"{category}.csv\"), \n",
    "                             index=False, encoding='utf-8')\n",
    "        \n",
    "        # Workflow-Bericht erstellen\n",
    "        report_path = os.path.join(output_dir, \"workflow_report.txt\")\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"AUTOMATISIERTER BAU-WORKFLOW BERICHT\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"PDF-Datei: {pdf_path}\\n\")\n",
    "            f.write(f\"Grundriss: {floorplan_path}\\n\")\n",
    "            f.write(f\"Textextraktion: {method}\\n\")\n",
    "            f.write(f\"Textlänge: {len(text)} Zeichen\\n\")\n",
    "            f.write(f\"SVG erstellt: {'Ja' if svg_path else 'Nein'}\\n\")\n",
    "            f.write(f\"Annotation erstellt: {'Ja' if workflow_results.get('annotated_svg') else 'Nein'}\\n\")\n",
    "            \n",
    "            if extracted_info:\n",
    "                f.write(f\"\\nExtrahierte Informationen:\\n\")\n",
    "                f.write(f\"- Materialien: {len(extracted_info.get('materials', []))}\\n\")\n",
    "                f.write(f\"- Räume: {len(extracted_info.get('rooms', []))}\\n\")\n",
    "                f.write(f\"- Maße: {len(extracted_info.get('measurements', []))}\\n\")\n",
    "                f.write(f\"- Positionen: {len(extracted_info.get('positions', []))}\\n\")\n",
    "            \n",
    "            if workflow_results['errors']:\n",
    "                f.write(f\"\\nFehler: {', '.join(workflow_results['errors'])}\\n\")\n",
    "        \n",
    "        workflow_results['success'] = len(workflow_results['errors']) == 0\n",
    "        \n",
    "        print(\"✅ Workflow abgeschlossen!\")\n",
    "        print(f\"📊 Bericht gespeichert: {report_path}\")\n",
    "        \n",
    "        return workflow_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        workflow_results['errors'].append(str(e))\n",
    "        print(f\"❌ Workflow-Fehler: {e}\")\n",
    "        return workflow_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ === AUTOMATISIERTER BAU-WORKFLOW GESTARTET ===\n",
      "📄 PDF: bauausschreibung.pdf\n",
      "🏠 Grundriss: grundriss.pdf\n",
      "📁 Ausgabe: ergebnisse\n",
      "\n",
      "🔍 Schritt 1: Text-Extraktion...\n",
      "❌ Workflow-Fehler: PDF-Datei nicht gefunden: bauausschreibung.pdf\n"
     ]
    }
   ],
   "source": [
    "# Einfacher Aufruf für kompletten Workflow\n",
    "results = process_construction_documents(\n",
    "    pdf_path=\"bauausschreibung.pdf\",\n",
    "    floorplan_path=\"grundriss.pdf\", \n",
    "    output_dir=\"ergebnisse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einfacher Aufruf des kompletten Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 🔍 Bonus-Workflow: Raster-PDF zu durchsuchbares PDF\n",
    "\n",
    "Separater Workflow zur Konvertierung von gescannten/Raster-PDFs in durchsuchbare PDFs mit OCR-Text-Layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raster_pdf_to_searchable(input_pdf_path, output_pdf_path=None, \n",
    "                                     language='deu+eng', dpi=300):\n",
    "    \"\"\"\n",
    "    Konvertiert eine Raster-PDF (gescannt) in eine durchsuchbare PDF mit OCR-Text-Layer.\n",
    "    \n",
    "    Args:\n",
    "        input_pdf_path (str): Pfad zur Eingabe-PDF\n",
    "        output_pdf_path (str): Pfad für Ausgabe-PDF (optional)\n",
    "        language (str): Tesseract Sprachcode\n",
    "        dpi (int): DPI für die Bildkonvertierung\n",
    "        \n",
    "    Returns:\n",
    "        str: Pfad zur erstellten durchsuchbaren PDF\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(input_pdf_path):\n",
    "        print(f\"❌ Eingabe-PDF nicht gefunden: {input_pdf_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Ausgabepfad bestimmen\n",
    "    if not output_pdf_path:\n",
    "        base_name = os.path.splitext(input_pdf_path)[0]\n",
    "        output_pdf_path = f\"{base_name}_searchable.pdf\"\n",
    "    \n",
    "    print(f\"🔄 Konvertiere Raster-PDF zu durchsuchbarer PDF...\")\n",
    "    print(f\"📄 Eingabe: {input_pdf_path}\")\n",
    "    print(f\"💾 Ausgabe: {output_pdf_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Schritt 1: Überprüfe ob bereits durchsuchbar\n",
    "        if is_pdf_searchable(input_pdf_path):\n",
    "            print(\"✅ PDF ist bereits durchsuchbar - kopiere Original\")\n",
    "            import shutil\n",
    "            shutil.copy2(input_pdf_path, output_pdf_path)\n",
    "            return output_pdf_path\n",
    "        \n",
    "        # Schritt 2: PDF zu Bildern konvertieren\n",
    "        print(\"🖼️ Konvertiere PDF-Seiten zu Bildern...\")\n",
    "        images = convert_from_path(input_pdf_path, dpi=dpi)\n",
    "        print(f\"📋 {len(images)} Seiten gefunden\")\n",
    "        \n",
    "        # Schritt 3: Einfachere Methode - Text extrahieren und neues PDF erstellen\n",
    "        print(\"🔍 Starte OCR...\")\n",
    "        \n",
    "        # Erstelle neues PDF-Dokument  \n",
    "        new_doc = fitz.open()\n",
    "        \n",
    "        for page_num, image in enumerate(images):\n",
    "            print(f\"  📄 Verarbeite Seite {page_num + 1}/{len(images)}\")\n",
    "            \n",
    "            # OCR für gesamten Text der Seite\n",
    "            page_text = pytesseract.image_to_string(\n",
    "                image, \n",
    "                lang=language,\n",
    "                config='--psm 1'\n",
    "            )\n",
    "            \n",
    "            # Neue Seite erstellen mit Original-Dimensionen\n",
    "            page_width = image.width * 72 / dpi\n",
    "            page_height = image.height * 72 / dpi\n",
    "            new_page = new_doc.new_page(width=page_width, height=page_height)\n",
    "            \n",
    "            # Original-Bild einfügen\n",
    "            import io\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            image.save(img_byte_arr, format='PNG')\n",
    "            img_bytes = img_byte_arr.getvalue()\n",
    "            \n",
    "            new_page.insert_image(fitz.Rect(0, 0, page_width, page_height), \n",
    "                                 stream=img_bytes)\n",
    "            \n",
    "            # Unsichtbaren Text hinzufügen (für Durchsuchbarkeit)\n",
    "            if page_text.strip():\n",
    "                # Text außerhalb des sichtbaren Bereichs platzieren\n",
    "                new_page.insert_text(\n",
    "                    (page_width + 10, 10),  # Außerhalb der Seite\n",
    "                    page_text,\n",
    "                    fontsize=1,  # Sehr kleine Schrift\n",
    "                    color=(1, 1, 1),  # Weiß (unsichtbar)\n",
    "                )\n",
    "        \n",
    "        # PDF speichern\n",
    "        new_doc.save(output_pdf_path, garbage=4, deflate=True)\n",
    "        new_doc.close()\n",
    "        \n",
    "        print(f\"✅ Durchsuchbare PDF erstellt: {output_pdf_path}\")\n",
    "        \n",
    "        # Validierung\n",
    "        if is_pdf_searchable(output_pdf_path):\n",
    "            print(\"✅ Validierung erfolgreich - PDF ist jetzt durchsuchbar!\")\n",
    "        else:\n",
    "            print(\"⚠️ Warnung: PDF möglicherweise nicht vollständig durchsuchbar\")\n",
    "        \n",
    "        return output_pdf_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Fehler bei der Konvertierung: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convert_pdfs_to_searchable(input_directory, output_directory=None):\n",
    "    \"\"\"\n",
    "    Batch-Konvertierung mehrerer PDF-Dateien zu durchsuchbaren PDFs.\n",
    "    \n",
    "    Args:\n",
    "        input_directory (str): Verzeichnis mit Eingabe-PDFs\n",
    "        output_directory (str): Ausgabeverzeichnis (optional)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Ergebnisse der Batch-Konvertierung\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(input_directory):\n",
    "        print(f\"❌ Eingabeverzeichnis nicht gefunden: {input_directory}\")\n",
    "        return None\n",
    "    \n",
    "    # Ausgabeverzeichnis bestimmen\n",
    "    if not output_directory:\n",
    "        output_directory = os.path.join(input_directory, \"searchable_pdfs\")\n",
    "    \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Finde alle PDF-Dateien\n",
    "    pdf_files = [f for f in os.listdir(input_directory) if f.lower().endswith('.pdf')]\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"❌ Keine PDF-Dateien in {input_directory} gefunden\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📁 Batch-Konvertierung von {len(pdf_files)} PDF-Dateien\")\n",
    "    print(f\"📥 Eingabe: {input_directory}\")\n",
    "    print(f\"📤 Ausgabe: {output_directory}\")\n",
    "    print()\n",
    "    \n",
    "    results = {\n",
    "        'total_files': len(pdf_files),\n",
    "        'converted': [],\n",
    "        'already_searchable': [],\n",
    "        'failed': [],\n",
    "        'processing_time': 0\n",
    "    }\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, pdf_file in enumerate(pdf_files):\n",
    "        print(f\"🔄 [{i+1}/{len(pdf_files)}] Verarbeite: {pdf_file}\")\n",
    "        \n",
    "        input_path = os.path.join(input_directory, pdf_file)\n",
    "        output_filename = f\"searchable_{pdf_file}\"\n",
    "        output_path = os.path.join(output_directory, output_filename)\n",
    "        \n",
    "        try:\n",
    "            result_path = convert_raster_pdf_to_searchable(input_path, output_path)\n",
    "            \n",
    "            if result_path:\n",
    "                if result_path == output_path:\n",
    "                    results['converted'].append(pdf_file)\n",
    "                else:\n",
    "                    results['already_searchable'].append(pdf_file)\n",
    "            else:\n",
    "                results['failed'].append(pdf_file)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Fehler bei {pdf_file}: {e}\")\n",
    "            results['failed'].append(pdf_file)\n",
    "        \n",
    "        print()  # Leerzeile zwischen Dateien\n",
    "    \n",
    "    results['processing_time'] = time.time() - start_time\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📊 BATCH-KONVERTIERUNG ABGESCHLOSSEN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"📄 Verarbeitete Dateien: {results['total_files']}\")\n",
    "    print(f\"✅ Konvertiert: {len(results['converted'])}\")\n",
    "    print(f\"✓ Bereits durchsuchbar: {len(results['already_searchable'])}\")\n",
    "    print(f\"❌ Fehlgeschlagen: {len(results['failed'])}\")\n",
    "    print(f\"⏱️ Verarbeitungszeit: {results['processing_time']:.1f} Sekunden\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEMO: RASTER-PDF ZU DURCHSUCHBARER PDF ===\n",
      "\n",
      "🔍 Teste Datei: Angebot_Schulzimmertuere.pdf\n",
      "📄 PDF-Status: Durchsuchbar\n",
      "📝 Gefundener Text: 1984 Zeichen\n",
      "✅ PDF ist bereits durchsuchbar\n",
      "--------------------------------------------------\n",
      "\n",
      "💡 BATCH-KONVERTIERUNG BEISPIEL:\n",
      "# Konvertiere alle PDFs in einem Ordner:\n",
      "# results = batch_convert_pdfs_to_searchable('mein_pdf_ordner')\n",
      "\n",
      "💡 EINZELNE DATEI BEISPIEL:\n",
      "# result = convert_raster_pdf_to_searchable('gescannte_datei.pdf')\n",
      "\n",
      "🎯 NUTZUNGSHINWEISE:\n",
      "• Funktioniert mit gescannten PDFs (Raster-Bildern)\n",
      "• Erkennt automatisch ob PDF bereits durchsuchbar ist\n",
      "• Behält Original-Bildqualität bei\n",
      "• Fügt unsichtbaren Text-Layer für Suchfunktion hinzu\n",
      "• Unterstützt Deutsch + Englisch OCR\n",
      "• Batch-Modus für mehrere Dateien verfügbar\n"
     ]
    }
   ],
   "source": [
    "# Demo der PDF-zu-durchsuchbar Konvertierung\n",
    "print(\"=== DEMO: RASTER-PDF ZU DURCHSUCHBARER PDF ===\")\n",
    "\n",
    "# Teste mit verfügbaren PDF-Dateien\n",
    "test_files = [\"Angebot_Schulzimmertuere.pdf\"]\n",
    "\n",
    "for test_file in test_files:\n",
    "    if os.path.exists(test_file):\n",
    "        print(f\"\\n🔍 Teste Datei: {test_file}\")\n",
    "        \n",
    "        # Überprüfe aktuellen Status\n",
    "        is_searchable = is_pdf_searchable(test_file)\n",
    "        \n",
    "        if not is_searchable:\n",
    "            print(\"📝 Konvertiere zu durchsuchbarer PDF...\")\n",
    "            result = convert_raster_pdf_to_searchable(test_file)\n",
    "            \n",
    "            if result:\n",
    "                print(f\"✅ Durchsuchbare PDF erstellt: {result}\")\n",
    "            else:\n",
    "                print(\"❌ Konvertierung fehlgeschlagen\")\n",
    "        else:\n",
    "            print(\"✅ PDF ist bereits durchsuchbar\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Beispiel für Batch-Konvertierung\n",
    "print(\"\\n💡 BATCH-KONVERTIERUNG BEISPIEL:\")\n",
    "print(\"# Konvertiere alle PDFs in einem Ordner:\")\n",
    "print(\"# results = batch_convert_pdfs_to_searchable('mein_pdf_ordner')\")\n",
    "print(\"\\n💡 EINZELNE DATEI BEISPIEL:\")\n",
    "print(\"# result = convert_raster_pdf_to_searchable('gescannte_datei.pdf')\")\n",
    "\n",
    "print(\"\\n🎯 NUTZUNGSHINWEISE:\")\n",
    "print(\"• Funktioniert mit gescannten PDFs (Raster-Bildern)\")\n",
    "print(\"• Erkennt automatisch ob PDF bereits durchsuchbar ist\")\n",
    "print(\"• Behält Original-Bildqualität bei\")\n",
    "print(\"• Fügt unsichtbaren Text-Layer für Suchfunktion hinzu\")\n",
    "print(\"• Unterstützt Deutsch + Englisch OCR\")\n",
    "print(\"• Batch-Modus für mehrere Dateien verfügbar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Eingabe-PDF nicht gefunden: gescannte_datei.pdf\n",
      "❌ Eingabeverzeichnis nicht gefunden: mein_pdf_ordner\n"
     ]
    }
   ],
   "source": [
    "# Einzelne Datei\n",
    "result = convert_raster_pdf_to_searchable('gescannte_datei.pdf')\n",
    "\n",
    "# Batch-Verarbeitung\n",
    "results = batch_convert_pdfs_to_searchable('mein_pdf_ordner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BKP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Bezeichnung</th>\n",
       "      <th>Kategorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Übergangspositionen</td>\n",
       "      <td>0 Grundstück &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Studien zur Grundstückbeurteilung</td>\n",
       "      <td>0 Grundstück &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vermessung, Vermarchung</td>\n",
       "      <td>0 Grundstück &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Geotechnische Gutachten</td>\n",
       "      <td>0 Grundstück &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Quartierplankosten</td>\n",
       "      <td>0 Grundstück &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>992</td>\n",
       "      <td>993</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>994</td>\n",
       "      <td>995</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>996</td>\n",
       "      <td>Spezialisten</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>997</td>\n",
       "      <td>998</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>999</td>\n",
       "      <td>Übriges</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Position                        Bezeichnung                     Kategorie\n",
       "0           0                Übergangspositionen  0 Grundstück > 00 Vorstudien\n",
       "1           1  Studien zur Grundstückbeurteilung  0 Grundstück > 00 Vorstudien\n",
       "2           2            Vermessung, Vermarchung  0 Grundstück > 00 Vorstudien\n",
       "3           3            Geotechnische Gutachten  0 Grundstück > 00 Vorstudien\n",
       "4           4                 Quartierplankosten  0 Grundstück > 00 Vorstudien\n",
       "..        ...                                ...                           ...\n",
       "531       992                                993    9 Ausstatung > 99 Honorare\n",
       "532       994                                995    9 Ausstatung > 99 Honorare\n",
       "533       996                       Spezialisten    9 Ausstatung > 99 Honorare\n",
       "534       997                                998    9 Ausstatung > 99 Honorare\n",
       "535       999                            Übriges    9 Ausstatung > 99 Honorare\n",
       "\n",
       "[536 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pfad zur heruntergeladenen CSV-Datei angeben\n",
    "csv_path = \"BKP-Plan.csv\"  # Passe den Dateinamen an, falls du anders gespeichert hast\n",
    "\n",
    "# CSV in DataFrame laden\n",
    "df_bkp = pd.read_csv(csv_path)\n",
    "\n",
    "# Ersten Überblick verschaffen\n",
    "#df_bkp.head(30)\n",
    "df_bkp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_annotation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
