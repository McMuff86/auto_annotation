{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Workflow for Processing Construction Tenders and Floor Plans\n",
    "\n",
    "Dieses Notebook implementiert einen automatisierten Workflow zur Verarbeitung von Bauausschreibungen und Grundrissen gem√§√ü der Projektbeschreibung im README.md.\n",
    "\n",
    "## Workflow-√úbersicht:\n",
    "\n",
    "1. **Input Verification** - PDF-Text extrahieren (pdfminer/PyMuPDF)\n",
    "2. **OCR mit Tesseract** - Falls kein Text gefunden wurde\n",
    "3. **Vektorisierung des Grundrisses** - Format pr√ºfen und ggf. vektorisieren\n",
    "4. **Textanalyse & Informationsextraktion** - NLP mit spaCy\n",
    "5. **Automatische Annotation** - Grundriss annotieren\n",
    "6. **Erweiterungen** - Zusammenfassung, Datenbankanbindung (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "\n",
    "Importiere alle ben√∂tigten Bibliotheken f√ºr den Workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Bibliotheken erfolgreich importiert!\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PDF processing\n",
    "from pdfminer.high_level import extract_text\n",
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Vector graphics\n",
    "import svgwrite\n",
    "\n",
    "# NLP\n",
    "import spacy\n",
    "\n",
    "# Set Tesseract path for Windows\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Display settings\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "print(\"Alle Bibliotheken erfolgreich importiert!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input Verification\n",
    "\n",
    "√úberpr√ºfe, ob die PDF bereits durchsuchbar ist und extrahiere Text mit pdfminer.six oder PyMuPDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versuche Textextraktion mit pdfminer.six...\n",
      "‚úì Text erfolgreich extrahiert (3121 Zeichen)\n",
      "Verwendete Methode: pdfminer\n",
      "Extrahierter Text (erste 200 Zeichen): Sample PDF\n",
      "This is a simple PDF Ô¨Åle. Fun fun fun.\n",
      "\n",
      "Lorem ipsum dolor  sit amet,  consectetuer  adipiscing elit.  Phasellus  facilisis odio  sed mi. \n",
      "Curabitur suscipit. Nullam vel nisi. Etiam semper i...\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path, method='auto'):\n",
    "    \"\"\"\n",
    "    Extrahiert Text aus einer PDF-Datei mit verschiedenen Methoden.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur PDF-Datei\n",
    "        method (str): 'auto', 'pdfminer', 'pymupdf' oder 'ocr'\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (extracted_text, method_used)\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"PDF-Datei nicht gefunden: {pdf_path}\")\n",
    "    \n",
    "    # Method 1: pdfminer.six\n",
    "    if method in ['auto', 'pdfminer']:\n",
    "        try:\n",
    "            print(\"Versuche Textextraktion mit pdfminer.six...\")\n",
    "            text = extract_text(pdf_path)\n",
    "            if text.strip():  # Check if meaningful text was extracted\n",
    "                print(f\"‚úì Text erfolgreich extrahiert ({len(text)} Zeichen)\")\n",
    "                return text, 'pdfminer'\n",
    "            else:\n",
    "                print(\"‚ö† Kein Text mit pdfminer gefunden\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† pdfminer Fehler: {e}\")\n",
    "    \n",
    "    # Method 2: PyMuPDF\n",
    "    if method in ['auto', 'pymupdf']:\n",
    "        try:\n",
    "            print(\"Versuche Textextraktion mit PyMuPDF...\")\n",
    "            doc = fitz.open(pdf_path)\n",
    "            text = \"\"\n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc[page_num]\n",
    "                text += page.get_text()\n",
    "            doc.close()\n",
    "            \n",
    "            if text.strip():\n",
    "                print(f\"‚úì Text erfolgreich extrahiert ({len(text)} Zeichen)\")\n",
    "                return text, 'pymupdf'\n",
    "            else:\n",
    "                print(\"‚ö† Kein Text mit PyMuPDF gefunden\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† PyMuPDF Fehler: {e}\")\n",
    "    \n",
    "    # Method 3: OCR fallback\n",
    "    if method in ['auto', 'ocr']:\n",
    "        print(\"Fallback: OCR wird verwendet...\")\n",
    "        return extract_text_with_ocr(pdf_path), 'ocr'\n",
    "    \n",
    "    return \"\", 'none'\n",
    "\n",
    "# Test der Funktion (mit Platzhalter)\n",
    "text, method = extract_text_from_pdf(\"example.pdf\")\n",
    "print(f\"Verwendete Methode: {method}\")\n",
    "print(f\"Extrahierter Text (erste 200 Zeichen): {text[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OCR mit Tesseract\n",
    "\n",
    "Konvertiere PDF-Seiten zu Bildern und extrahiere Text mit Tesseract OCR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_ocr(pdf_path, language='deu+eng'):\n",
    "    \"\"\"\n",
    "    Extrahiert Text aus PDF mit OCR (Tesseract).\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur PDF-Datei\n",
    "        language (str): Tesseract Sprachcode (deu=Deutsch, eng=Englisch)\n",
    "        \n",
    "    Returns:\n",
    "        str: Extrahierter Text\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Konvertiere PDF zu Bildern...\")\n",
    "        # PDF zu Bildern konvertieren\n",
    "        images = convert_from_path(pdf_path, dpi=300)  # H√∂here DPI f√ºr bessere OCR\n",
    "        \n",
    "        extracted_text = \"\"\n",
    "        \n",
    "        print(f\"Verarbeite {len(images)} Seiten mit OCR...\")\n",
    "        for i, image in enumerate(images):\n",
    "            print(f\"  Seite {i+1}/{len(images)}\")\n",
    "            \n",
    "            # OCR auf jedes Bild anwenden\n",
    "            page_text = pytesseract.image_to_string(\n",
    "                image, \n",
    "                lang=language,\n",
    "                config='--psm 1'  # Page segmentation mode\n",
    "            )\n",
    "            \n",
    "            extracted_text += f\"\\n--- Seite {i+1} ---\\n{page_text}\\n\"\n",
    "        \n",
    "        print(f\"‚úì OCR abgeschlossen ({len(extracted_text)} Zeichen extrahiert)\")\n",
    "        return extracted_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå OCR Fehler: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konvertiere PDF zu Bildern...\n",
      "Verarbeite 1 Seiten mit OCR...\n",
      "  Seite 1/1\n",
      "‚úì OCR abgeschlossen (2872 Zeichen extrahiert)\n",
      "OCR Text (erste 200 Zeichen): \n",
      "--- Seite 1 ---\n",
      "sample PDF\n",
      "\n",
      "This ƒ±s a simple PDF file. Fun fun fun.\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Phasellus facilisis odio sed mi.\n",
      "Curabitur suscipit. Nullam vel nisi. Et...\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image_for_ocr(image):\n",
    "    \"\"\"\n",
    "    Verbessert ein Bild f√ºr bessere OCR-Ergebnisse.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image oder numpy array\n",
    "        \n",
    "    Returns:\n",
    "        Processed image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Konvertiere zu numpy array falls n√∂tig\n",
    "    if hasattr(image, 'mode'):\n",
    "        image = np.array(image)\n",
    "    \n",
    "    # Zu Graustufen konvertieren\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Rauschen reduzieren\n",
    "    denoised = cv2.medianBlur(gray, 3)\n",
    "    \n",
    "    # Kontrast verbessern\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "# Test der OCR-Funktion (mit Platzhalter)\n",
    "ocr_text = extract_text_with_ocr(\"example.pdf\")\n",
    "print(f\"OCR Text (erste 200 Zeichen): {ocr_text[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vektorisierung des Grundrisses\n",
    "\n",
    "√úberpr√ºfe das Dateiformat des Grundrisses und vektorisiere bei Bedarf mit OpenCV und Potrace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_format(file_path):\n",
    "    \"\"\"\n",
    "    √úberpr√ºft das Dateiformat einer Datei.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Pfad zur Datei\n",
    "        \n",
    "    Returns:\n",
    "        str: Dateiformat ('pdf', 'svg', 'dxf', 'image', 'unknown')\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Datei nicht gefunden: {file_path}\")\n",
    "    \n",
    "    # Get file extension\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    ext = ext.lower()\n",
    "    \n",
    "    format_mapping = {\n",
    "        '.pdf': 'pdf',\n",
    "        '.svg': 'svg',\n",
    "        '.dxf': 'dxf',\n",
    "        '.png': 'image',\n",
    "        '.jpg': 'image',\n",
    "        '.jpeg': 'image',\n",
    "        '.tiff': 'image',\n",
    "        '.tif': 'image',\n",
    "        '.bmp': 'image'\n",
    "    }\n",
    "    \n",
    "    return format_mapping.get(ext, 'unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_floorplan(file_path, output_dir=\"output\"):\n",
    "    \"\"\"\n",
    "    Vektorisiert einen Grundriss falls n√∂tig.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Pfad zur Grundriss-Datei\n",
    "        output_dir (str): Ausgabeverzeichnis\n",
    "        \n",
    "    Returns:\n",
    "        str: Pfad zur vektorisierten SVG-Datei\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ausgabeverzeichnis erstellen\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Dateiformat √ºberpr√ºfen\n",
    "    file_format = check_file_format(file_path)\n",
    "    print(f\"Erkanntes Dateiformat: {file_format}\")\n",
    "    \n",
    "    # Base filename for output\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    svg_output_path = os.path.join(output_dir, f\"{base_name}_vectorized.svg\")\n",
    "    \n",
    "    # Bereits SVG?\n",
    "    if file_format == 'svg':\n",
    "        print(\"‚úì Datei ist bereits im SVG-Format\")\n",
    "        return file_path\n",
    "    \n",
    "    # PDF mit Vektorpfaden?\n",
    "    elif file_format == 'pdf':\n",
    "        if check_pdf_for_vectors(file_path):\n",
    "            print(\"‚úì PDF enth√§lt Vektorpfade\")\n",
    "            # TODO: PDF Vektoren zu SVG konvertieren\n",
    "            # F√ºr jetzt: Fallback zu Rasterbild-Vektorisierung\n",
    "            return vectorize_raster_to_svg(file_path, svg_output_path)\n",
    "        else:\n",
    "            print(\"‚ö† PDF enth√§lt keine Vektorpfade - verwende Rasterbild-Vektorisierung\")\n",
    "            return vectorize_raster_to_svg(file_path, svg_output_path)\n",
    "    \n",
    "    # Rasterbild\n",
    "    elif file_format == 'image':\n",
    "        print(\"‚Ñπ Rasterbild erkannt - starte Vektorisierung\")\n",
    "        return vectorize_raster_to_svg(file_path, svg_output_path)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Nicht unterst√ºtztes Dateiformat: {file_format}\")\n",
    "\n",
    "def check_pdf_for_vectors(pdf_path):\n",
    "    \"\"\"\n",
    "    √úberpr√ºft, ob eine PDF-Datei Vektorpfade enth√§lt.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur PDF-Datei\n",
    "        \n",
    "    Returns:\n",
    "        bool: True wenn Vektorpfade gefunden wurden\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        for page_num in range(min(3, len(doc))):  # Nur erste 3 Seiten pr√ºfen\n",
    "            page = doc[page_num]\n",
    "            paths = page.get_drawings()\n",
    "            if paths:\n",
    "                doc.close()\n",
    "                return True\n",
    "        doc.close()\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim √úberpr√ºfen der PDF-Vektoren: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== HILFSFUNKTIONEN F√úR VERBESSERTE VEKTORISIERUNG =====\n",
    "\n",
    "def detect_text_regions(image):\n",
    "    \"\"\"\n",
    "    Erkennt Textbereiche im Bild um sie von der Linienvektorisierung auszuschlie√üen.\n",
    "    \n",
    "    Args:\n",
    "        image: Original-Bild (farbig oder grau)\n",
    "        \n",
    "    Returns:\n",
    "        Binary mask der Textbereiche oder None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Zu Graustufen konvertieren\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # MSER (Maximally Stable Extremal Regions) f√ºr Text-Erkennung\n",
    "        mser = cv2.MSER_create(\n",
    "            _min_area=10,      # Mindestfl√§che\n",
    "            _max_area=5000,    # Maximale Fl√§che\n",
    "            _delta=3           # Empfindlichkeit\n",
    "        )\n",
    "        \n",
    "        regions, _ = mser.detectRegions(gray)\n",
    "        \n",
    "        # Maske erstellen\n",
    "        text_mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "        \n",
    "        for region in regions:\n",
    "            # Bounding Box der Region\n",
    "            x, y, w, h = cv2.boundingRect(region.reshape(-1, 1, 2))\n",
    "            \n",
    "            # Filter: Text√§hnliche Dimensionen\n",
    "            aspect_ratio = w / h if h > 0 else 0\n",
    "            if 0.1 < aspect_ratio < 10 and 5 < w < 200 and 5 < h < 50:\n",
    "                # Region als Text markieren\n",
    "                cv2.rectangle(text_mask, (x-2, y-2), (x+w+2, y+h+2), 255, -1)\n",
    "        \n",
    "        # Morphologische Operationen um Text-Regionen zu verbinden\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 2))\n",
    "        text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        return text_mask\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Text-Erkennung fehlgeschlagen: {e}\")\n",
    "        return None\n",
    "\n",
    "def detect_wall_regions(binary_image):\n",
    "    \"\"\"\n",
    "    Erkennt dicke schwarze Bereiche als W√§nde.\n",
    "    \n",
    "    Args:\n",
    "        binary_image: Bin√§res Eingabebild\n",
    "        \n",
    "    Returns:\n",
    "        Binary mask der Wandbereiche oder None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Morphologische Operationen um dicke Linien zu erkennen\n",
    "        # Horizontale Strukturen\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))\n",
    "        horizontal_walls = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        \n",
    "        # Vertikale Strukturen  \n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 15))\n",
    "        vertical_walls = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        \n",
    "        # Kombiniere horizontale und vertikale W√§nde\n",
    "        wall_regions = cv2.bitwise_or(horizontal_walls, vertical_walls)\n",
    "        \n",
    "        # Zus√§tzliche Filterung: Entferne sehr kleine Bereiche\n",
    "        contours, _ = cv2.findContours(wall_regions, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        filtered_walls = np.zeros_like(wall_regions)\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 100:  # Mindestfl√§che f√ºr W√§nde\n",
    "                cv2.fillPoly(filtered_walls, [contour], 255)\n",
    "        \n",
    "        return filtered_walls\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Wand-Erkennung fehlgeschlagen: {e}\")\n",
    "        return None\n",
    "\n",
    "def detect_and_merge_lines(image):\n",
    "    \"\"\"\n",
    "    Intelligente Linienerkennung mit Verschmelzung √§hnlicher Linien.\n",
    "    \n",
    "    Args:\n",
    "        image: Bereinigtes bin√§res Bild\n",
    "        \n",
    "    Returns:\n",
    "        Liste verschmolzener Linien\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Hough-Linien erkennen mit strengeren Parametern\n",
    "        lines = cv2.HoughLinesP(\n",
    "            image, \n",
    "            rho=1, \n",
    "            theta=np.pi/180, \n",
    "            threshold=30,        # H√∂here Schwelle\n",
    "            minLineLength=20,    # Mindestl√§nge\n",
    "            maxLineGap=5         # Kleinere L√ºcken\n",
    "        )\n",
    "        \n",
    "        if lines is None or len(lines) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Linien in einfacheres Format konvertieren\n",
    "        line_list = []\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            line_list.append((x1, y1, x2, y2))\n",
    "        \n",
    "        # Linien nach √Ñhnlichkeit gruppieren und verschmelzen\n",
    "        merged_lines = merge_similar_lines(line_list)\n",
    "        \n",
    "        print(f\"  Linien: {len(line_list)} ‚Üí {len(merged_lines)} (nach Verschmelzung)\")\n",
    "        return merged_lines\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Linienerkennung fehlgeschlagen: {e}\")\n",
    "        return []\n",
    "\n",
    "def merge_similar_lines(lines, angle_threshold=5, distance_threshold=10):\n",
    "    \"\"\"\n",
    "    Verschmilzt √§hnliche/kollineare Linien.\n",
    "    \n",
    "    Args:\n",
    "        lines: Liste von Linien (x1, y1, x2, y2)\n",
    "        angle_threshold: Winkel-Toleranz in Grad\n",
    "        distance_threshold: Abstand-Toleranz in Pixeln\n",
    "        \n",
    "    Returns:\n",
    "        Liste verschmolzener Linien\n",
    "    \"\"\"\n",
    "    if not lines:\n",
    "        return []\n",
    "    \n",
    "    merged = []\n",
    "    used = set()\n",
    "    \n",
    "    for i, line1 in enumerate(lines):\n",
    "        if i in used:\n",
    "            continue\n",
    "            \n",
    "        x1, y1, x2, y2 = line1\n",
    "        \n",
    "        # Suche √§hnliche Linien\n",
    "        similar_lines = [line1]\n",
    "        used.add(i)\n",
    "        \n",
    "        for j, line2 in enumerate(lines):\n",
    "            if j in used or i == j:\n",
    "                continue\n",
    "                \n",
    "            if are_lines_similar(line1, line2, angle_threshold, distance_threshold):\n",
    "                similar_lines.append(line2)\n",
    "                used.add(j)\n",
    "        \n",
    "        # Verschmelze √§hnliche Linien zu einer\n",
    "        if len(similar_lines) > 1:\n",
    "            merged_line = merge_line_group(similar_lines)\n",
    "            merged.append(merged_line)\n",
    "        else:\n",
    "            merged.append(line1)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def are_lines_similar(line1, line2, angle_threshold, distance_threshold):\n",
    "    \"\"\"\n",
    "    √úberpr√ºft ob zwei Linien √§hnlich sind (√§hnlicher Winkel und nahe beieinander).\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "    \n",
    "    # Winkel berechnen\n",
    "    angle1 = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "    angle2 = np.arctan2(y4 - y3, x4 - x3) * 180 / np.pi\n",
    "    \n",
    "    # Winkel-Differenz (ber√ºcksichtige 180¬∞-Periodizit√§t)\n",
    "    angle_diff = abs(angle1 - angle2)\n",
    "    angle_diff = min(angle_diff, 180 - angle_diff)\n",
    "    \n",
    "    if angle_diff > angle_threshold:\n",
    "        return False\n",
    "    \n",
    "    # Abstand zwischen Linien berechnen\n",
    "    # Vereinfacht: Abstand zwischen Mittelpunkten\n",
    "    mid1 = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "    mid2 = ((x3 + x4) / 2, (y3 + y4) / 2)\n",
    "    distance = np.sqrt((mid1[0] - mid2[0])**2 + (mid1[1] - mid2[1])**2)\n",
    "    \n",
    "    return distance < distance_threshold\n",
    "\n",
    "def merge_line_group(lines):\n",
    "    \"\"\"\n",
    "    Verschmilzt eine Gruppe √§hnlicher Linien zu einer einzigen Linie.\n",
    "    \"\"\"\n",
    "    # Sammle alle Endpunkte\n",
    "    points = []\n",
    "    for x1, y1, x2, y2 in lines:\n",
    "        points.extend([(x1, y1), (x2, y2)])\n",
    "    \n",
    "    # Finde die beiden √§u√üersten Punkte\n",
    "    points = np.array(points)\n",
    "    \n",
    "    # Hauptachse der Punkte finden (PCA)\n",
    "    mean_point = np.mean(points, axis=0)\n",
    "    centered_points = points - mean_point\n",
    "    \n",
    "    # SVD f√ºr Hauptrichtung\n",
    "    _, _, vh = np.linalg.svd(centered_points)\n",
    "    direction = vh[0]\n",
    "    \n",
    "    # Projiziere alle Punkte auf die Hauptachse\n",
    "    projections = np.dot(centered_points, direction)\n",
    "    \n",
    "    # √Ñu√üerste Projektionen finden\n",
    "    min_proj = np.min(projections)\n",
    "    max_proj = np.max(projections)\n",
    "    \n",
    "    # Zur√ºck zu Koordinaten\n",
    "    start_point = mean_point + min_proj * direction\n",
    "    end_point = mean_point + max_proj * direction\n",
    "    \n",
    "    return (int(start_point[0]), int(start_point[1]), \n",
    "            int(end_point[0]), int(end_point[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SVG-ERSTELLUNGSFUNKTIONEN =====\n",
    "\n",
    "def add_wall_hatches(dwg, wall_regions, width, height):\n",
    "    \"\"\"\n",
    "    F√ºgt W√§nde als Schraffuren zum SVG hinzu.\n",
    "    \n",
    "    Args:\n",
    "        dwg: SVG Drawing Objekt\n",
    "        wall_regions: Binary mask der Wandbereiche\n",
    "        width, height: Bildabmessungen\n",
    "        \n",
    "    Returns:\n",
    "        Anzahl der hinzugef√ºgten W√§nde\n",
    "    \"\"\"\n",
    "    if wall_regions is None:\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        # Schraffur-Pattern definieren\n",
    "        pattern_id = \"wallHatch\"\n",
    "        pattern = dwg.defs.add(dwg.pattern(\n",
    "            id=pattern_id,\n",
    "            patternUnits=\"userSpaceOnUse\",\n",
    "            size=(6, 6)\n",
    "        ))\n",
    "        \n",
    "        # Diagonale Linien f√ºr Schraffur\n",
    "        pattern.add(dwg.line(start=(0, 0), end=(6, 6), stroke=\"black\", stroke_width=\"0.5\"))\n",
    "        pattern.add(dwg.line(start=(0, 6), end=(6, 0), stroke=\"black\", stroke_width=\"0.5\"))\n",
    "        \n",
    "        # Wandkonturen finden\n",
    "        contours, _ = cv2.findContours(wall_regions, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        wall_count = 0\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 50:  # Nur gr√∂√üere W√§nde\n",
    "                # Kontur vereinfachen\n",
    "                epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "                approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "                \n",
    "                if len(approx) >= 3:\n",
    "                    # Path f√ºr SVG erstellen\n",
    "                    path_data = f\"M {approx[0][0][0]},{approx[0][0][1]}\"\n",
    "                    for point in approx[1:]:\n",
    "                        path_data += f\" L {point[0][0]},{point[0][1]}\"\n",
    "                    path_data += \" Z\"\n",
    "                    \n",
    "                    # Wand mit Schraffur hinzuf√ºgen\n",
    "                    dwg.add(dwg.path(d=path_data, \n",
    "                                   fill=f\"url(#{pattern_id})\",\n",
    "                                   stroke=\"black\", \n",
    "                                   stroke_width=\"2\"))\n",
    "                    wall_count += 1\n",
    "        \n",
    "        return wall_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Wand-Schraffuren fehlgeschlagen: {e}\")\n",
    "        return 0\n",
    "\n",
    "def add_lines_to_svg(dwg, lines):\n",
    "    \"\"\"\n",
    "    F√ºgt bereinigte Linien zum SVG hinzu.\n",
    "    \n",
    "    Args:\n",
    "        dwg: SVG Drawing Objekt\n",
    "        lines: Liste von Linien (x1, y1, x2, y2)\n",
    "        \n",
    "    Returns:\n",
    "        Anzahl der hinzugef√ºgten Linien\n",
    "    \"\"\"\n",
    "    line_count = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line\n",
    "        \n",
    "        # Linenl√§nge pr√ºfen\n",
    "        length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        if length > 10:  # Mindestl√§nge\n",
    "            dwg.add(dwg.line(\n",
    "                start=(int(x1), int(y1)), \n",
    "                end=(int(x2), int(y2)),\n",
    "                stroke=\"black\", \n",
    "                stroke_width=\"1\",\n",
    "                stroke_linecap=\"round\"\n",
    "            ))\n",
    "            line_count += 1\n",
    "    \n",
    "    return line_count\n",
    "\n",
    "def detect_important_contours(image, width, height):\n",
    "    \"\"\"\n",
    "    Erkennt wichtige Konturen ohne √úberlappungen.\n",
    "    \n",
    "    Args:\n",
    "        image: Bereinigtes bin√§res Bild\n",
    "        width, height: Bildabmessungen\n",
    "        \n",
    "    Returns:\n",
    "        Liste wichtiger Konturen\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Konturen finden mit Hierarchie\n",
    "        contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        important_contours = []\n",
    "        min_area = (width * height) * 0.0001  # 0.01% der Gesamtfl√§che\n",
    "        max_area = (width * height) * 0.5     # 50% der Gesamtfl√§che\n",
    "        \n",
    "        for i, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            \n",
    "            # Filter nach Fl√§che\n",
    "            if not (min_area < area < max_area):\n",
    "                continue\n",
    "            \n",
    "            # Filter nach Seitenverh√§ltnis (vermeidet sehr schmale Objekte)\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else float('inf')\n",
    "            if aspect_ratio > 20:  # Zu schmale Objekte ausschlie√üen\n",
    "                continue\n",
    "            \n",
    "            # Filter nach Kompaktheit (vermeidet sehr verzweigte Formen)\n",
    "            if perimeter > 0:\n",
    "                compactness = 4 * np.pi * area / (perimeter * perimeter)\n",
    "                if compactness < 0.01:  # Zu verzweigte Formen ausschlie√üen\n",
    "                    continue\n",
    "            \n",
    "            # √Ñu√üere Konturen bevorzugen (Hierarchie pr√ºfen)\n",
    "            if hierarchy is not None:\n",
    "                parent = hierarchy[0][i][3]\n",
    "                if parent == -1 or len(important_contours) < 50:  # √Ñu√üere Konturen oder Limit\n",
    "                    important_contours.append(contour)\n",
    "            else:\n",
    "                important_contours.append(contour)\n",
    "        \n",
    "        return important_contours[:100]  # Maximal 100 Konturen\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Kontur-Erkennung fehlgeschlagen: {e}\")\n",
    "        return []\n",
    "\n",
    "def add_contours_to_svg(dwg, contours):\n",
    "    \"\"\"\n",
    "    F√ºgt wichtige Konturen zum SVG hinzu.\n",
    "    \n",
    "    Args:\n",
    "        dwg: SVG Drawing Objekt\n",
    "        contours: Liste von OpenCV Konturen\n",
    "        \n",
    "    Returns:\n",
    "        Anzahl der hinzugef√ºgten Konturen\n",
    "    \"\"\"\n",
    "    contour_count = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Kontur vereinfachen\n",
    "        epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        \n",
    "        if len(approx) >= 3:\n",
    "            # Path erstellen\n",
    "            path_data = f\"M {approx[0][0][0]},{approx[0][0][1]}\"\n",
    "            for point in approx[1:]:\n",
    "                path_data += f\" L {point[0][0]},{point[0][1]}\"\n",
    "            path_data += \" Z\"\n",
    "            \n",
    "            dwg.add(dwg.path(d=path_data, \n",
    "                           fill=\"none\", \n",
    "                           stroke=\"gray\", \n",
    "                           stroke_width=\"0.5\",\n",
    "                           stroke_dasharray=\"2,2\"))\n",
    "            contour_count += 1\n",
    "    \n",
    "    return contour_count\n",
    "\n",
    "def add_text_to_svg(dwg, image, text_mask):\n",
    "    \"\"\"\n",
    "    Extrahiert Text mit OCR und f√ºgt ihn als echten Text zum SVG hinzu.\n",
    "    \n",
    "    Args:\n",
    "        dwg: SVG Drawing Objekt\n",
    "        image: Original-Bild\n",
    "        text_mask: Maske der Textbereiche\n",
    "        \n",
    "    Returns:\n",
    "        Anzahl der hinzugef√ºgten Texte\n",
    "    \"\"\"\n",
    "    if text_mask is None:\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        # Textbereiche finden\n",
    "        contours, _ = cv2.findContours(text_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        text_count = 0\n",
    "        \n",
    "        for contour in contours:\n",
    "            # Bounding Box der Textregion\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Mindestgr√∂√üe f√ºr Text\n",
    "            if w < 10 or h < 5:\n",
    "                continue\n",
    "            \n",
    "            # Textregion aus Bild ausschneiden\n",
    "            text_region = image[y:y+h, x:x+w]\n",
    "            \n",
    "            try:\n",
    "                # OCR auf die Textregion anwenden\n",
    "                text_content = pytesseract.image_to_string(\n",
    "                    text_region, \n",
    "                    lang='deu+eng',\n",
    "                    config='--psm 8 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz√§√∂√º√Ñ√ñ√ú√ü0123456789.,- '\n",
    "                ).strip()\n",
    "                \n",
    "                # Nur hinzuf√ºgen wenn sinnvoller Text erkannt wurde\n",
    "                if len(text_content) > 1 and any(c.isalnum() for c in text_content):\n",
    "                    # Schriftgr√∂√üe basierend auf Texth√∂he sch√§tzen\n",
    "                    font_size = max(8, min(16, h * 0.7))\n",
    "                    \n",
    "                    # Text zum SVG hinzuf√ºgen\n",
    "                    dwg.add(dwg.text(\n",
    "                        text_content,\n",
    "                        insert=(x, y + h * 0.8),  # Baseline-korrigierte Position\n",
    "                        font_size=f\"{font_size}px\",\n",
    "                        font_family=\"Arial, sans-serif\",\n",
    "                        fill=\"blue\"\n",
    "                    ))\n",
    "                    text_count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # Einzelne OCR-Fehler ignorieren\n",
    "                continue\n",
    "        \n",
    "        return text_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Warnung: Text-Extraktion fehlgeschlagen: {e}\")\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erkanntes Dateiformat: pdf\n",
      "‚ö† PDF enth√§lt keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Textbereiche...\n",
      "  Warnung: Text-Erkennung fehlgeschlagen: '_min_area' is an invalid keyword argument for MSER_create()\n",
      "Erkenne W√§nde...\n",
      "Erkenne und verschmelze Linien...\n",
      "  Linien: 815 ‚Üí 387 (nach Verschmelzung)\n",
      "Erkenne wichtige Konturen...\n",
      "Extrahiere und f√ºge Text hinzu...\n",
      "‚úì Verbessertes SVG erstellt: output\\example_floorplan2_vectorized.svg\n",
      "  W√§nde: 107, Linien: 387, Konturen: 24, Texte: 0\n",
      "Vektorisierter Grundriss: output\\example_floorplan2_vectorized.svg\n"
     ]
    }
   ],
   "source": [
    "def vectorize_raster_to_svg(image_path, output_path):\n",
    "    \"\"\"\n",
    "    Verbesserte Konvertierung eines Rasterbilds zu SVG f√ºr Architekturpl√§ne.\n",
    "    \n",
    "    Features:\n",
    "    - Text-Erkennung und -Erhaltung\n",
    "    - Intelligente Linienverschmelzung\n",
    "    - Wand-Schraffuren f√ºr dicke schwarze Bereiche\n",
    "    - Reduzierung √ºberlappender Geometrien\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Pfad zum Eingabebild\n",
    "        output_path (str): Pfad f√ºr die Ausgabe-SVG\n",
    "        \n",
    "    Returns:\n",
    "        str: Pfad zur erstellten SVG-Datei\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Lade das Bild\n",
    "        if image_path.endswith('.pdf'):\n",
    "            images = convert_from_path(image_path, dpi=300)\n",
    "            image = np.array(images[0])\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(\"Bild konnte nicht geladen werden\")\n",
    "        \n",
    "        # Original f√ºr Text-Erkennung behalten\n",
    "        original_image = image.copy()\n",
    "        \n",
    "        # Bildverarbeitung f√ºr technische Zeichnungen\n",
    "        processed_image = preprocess_for_architectural_drawings(image)\n",
    "        height, width = processed_image.shape\n",
    "        \n",
    "        # 1. TEXT-ERKENNUNG UND -FILTER\n",
    "        print(\"Erkenne Textbereiche...\")\n",
    "        text_mask = detect_text_regions(original_image)\n",
    "        \n",
    "        # 2. WAND-ERKENNUNG (dicke schwarze Bereiche)\n",
    "        print(\"Erkenne W√§nde...\")\n",
    "        wall_regions = detect_wall_regions(processed_image)\n",
    "        \n",
    "        # 3. BEREINIGTES BILD F√úR LINIENERKENNUNG\n",
    "        # Entferne Text und W√§nde aus der Linienerkennung\n",
    "        lines_image = processed_image.copy()\n",
    "        if text_mask is not None:\n",
    "            lines_image = cv2.bitwise_and(lines_image, cv2.bitwise_not(text_mask))\n",
    "        if wall_regions is not None:\n",
    "            lines_image = cv2.bitwise_and(lines_image, cv2.bitwise_not(wall_regions))\n",
    "        \n",
    "        # SVG erstellen\n",
    "        dwg = svgwrite.Drawing(output_path, size=(f\"{width}px\", f\"{height}px\"))\n",
    "        \n",
    "        # 4. W√ÑNDE ALS SCHRAFFUREN HINZUF√úGEN\n",
    "        wall_count = add_wall_hatches(dwg, wall_regions, width, height)\n",
    "        \n",
    "        # 5. INTELLIGENTE LINIENERKENNUNG\n",
    "        print(\"Erkenne und verschmelze Linien...\")\n",
    "        cleaned_lines = detect_and_merge_lines(lines_image)\n",
    "        line_count = add_lines_to_svg(dwg, cleaned_lines)\n",
    "        \n",
    "        # 6. WICHTIGE KONTUREN (ohne √úberlappungen)\n",
    "        print(\"Erkenne wichtige Konturen...\")\n",
    "        important_contours = detect_important_contours(lines_image, width, height)\n",
    "        contour_count = add_contours_to_svg(dwg, important_contours)\n",
    "        \n",
    "        # 7. TEXT HINZUF√úGEN\n",
    "        print(\"Extrahiere und f√ºge Text hinzu...\")\n",
    "        text_count = add_text_to_svg(dwg, original_image, text_mask)\n",
    "        \n",
    "        # SVG speichern\n",
    "        dwg.save()\n",
    "        print(f\"‚úì Verbessertes SVG erstellt: {output_path}\")\n",
    "        print(f\"  W√§nde: {wall_count}, Linien: {line_count}, Konturen: {contour_count}, Texte: {text_count}\")\n",
    "        return output_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler bei der verbesserten Vektorisierung: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_for_architectural_drawings(image):\n",
    "    \"\"\"\n",
    "    Spezielle Bildvorverarbeitung f√ºr Architekturzeichnungen und technische Pl√§ne.\n",
    "    \n",
    "    Args:\n",
    "        image: Eingabebild (numpy array)\n",
    "        \n",
    "    Returns:\n",
    "        Vorverarbeitetes bin√§res Bild\n",
    "    \"\"\"\n",
    "    \n",
    "    # Zu Graustufen konvertieren\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Kontrast verbessern\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Leichter Gau√üscher Weichzeichner um Rauschen zu reduzieren\n",
    "    blurred = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
    "    \n",
    "    # Zwei verschiedene Schwellenwert-Methoden kombinieren\n",
    "    # 1. Adaptive Schwellenwert f√ºr lokale Variationen\n",
    "    adaptive = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # 2. Otsu-Schwellenwert f√ºr globale Binarisierung\n",
    "    _, otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Kombiniere beide Methoden\n",
    "    combined = cv2.bitwise_and(adaptive, otsu)\n",
    "    \n",
    "    # Morphologische Operationen um Linien zu verbessern\n",
    "    # Kleiner Kernel f√ºr feine Details\n",
    "    kernel_small = np.ones((2,2), np.uint8)\n",
    "    # Gr√∂√üerer Kernel f√ºr Linien\n",
    "    kernel_line = cv2.getStructuringElement(cv2.MORPH_RECT, (3,1))\n",
    "    \n",
    "    # Schlie√üe kleine L√ºcken in Linien\n",
    "    closed = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel_small)\n",
    "    \n",
    "    # Entferne kleine Artefakte\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_small)\n",
    "    \n",
    "    # Invertiere falls n√∂tig (schwarze Linien auf wei√üem Hintergrund)\n",
    "    # √úberpr√ºfe welche Farbe mehr Pixel hat\n",
    "    if np.sum(opened == 0) < np.sum(opened == 255):\n",
    "        opened = cv2.bitwise_not(opened)\n",
    "    \n",
    "    return opened\n",
    "\n",
    "# Test der Vektorisierungsfunktion (mit Platzhalter)\n",
    "svg_path = vectorize_floorplan(\"example_floorplan2.pdf\")\n",
    "print(f\"Vektorisierter Grundriss: {svg_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ === TEST DER VERBESSERTEN VEKTORISIERUNG ===\n",
      "\n",
      "üìÑ Teste mit: example_floorplan.pdf\n",
      "--------------------------------------------------\n",
      "Erkanntes Dateiformat: pdf\n",
      "‚ö† PDF enth√§lt keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Textbereiche...\n",
      "  Warnung: Text-Erkennung fehlgeschlagen: '_min_area' is an invalid keyword argument for MSER_create()\n",
      "Erkenne W√§nde...\n",
      "Erkenne und verschmelze Linien...\n",
      "  Linien: 104 ‚Üí 52 (nach Verschmelzung)\n",
      "Erkenne wichtige Konturen...\n",
      "Extrahiere und f√ºge Text hinzu...\n",
      "‚úì Verbessertes SVG erstellt: output_improved\\example_floorplan_vectorized.svg\n",
      "  W√§nde: 30, Linien: 52, Konturen: 0, Texte: 0\n",
      "‚úÖ Verbessertes SVG erstellt: output_improved\\example_floorplan_vectorized.svg\n",
      "üìä Dateigr√∂√üe: 10.4 KB\n",
      "\n",
      "üìÑ Teste mit: example_floorplan2.pdf\n",
      "--------------------------------------------------\n",
      "Erkanntes Dateiformat: pdf\n",
      "‚ö† PDF enth√§lt keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Textbereiche...\n",
      "  Warnung: Text-Erkennung fehlgeschlagen: '_min_area' is an invalid keyword argument for MSER_create()\n",
      "Erkenne W√§nde...\n",
      "Erkenne und verschmelze Linien...\n",
      "  Linien: 815 ‚Üí 387 (nach Verschmelzung)\n",
      "Erkenne wichtige Konturen...\n",
      "Extrahiere und f√ºge Text hinzu...\n",
      "‚úì Verbessertes SVG erstellt: output_improved\\example_floorplan2_vectorized.svg\n",
      "  W√§nde: 107, Linien: 387, Konturen: 24, Texte: 0\n",
      "‚úÖ Verbessertes SVG erstellt: output_improved\\example_floorplan2_vectorized.svg\n",
      "üìä Dateigr√∂√üe: 59.7 KB\n",
      "\n",
      "üí° VERBESSERUNGEN:\n",
      "‚úì Text-Erkennung verhindert √úbervektorisierung von Beschriftungen\n",
      "‚úì W√§nde werden als Schraffuren dargestellt\n",
      "‚úì Intelligente Linienverschmelzung reduziert √úberlappungen\n",
      "‚úì Wichtige Konturen werden gefiltert\n",
      "‚úì OCR-extrahierter Text wird als echte SVG-Texte eingef√ºgt\n",
      "\n",
      "üéØ N√ÑCHSTE SCHRITTE:\n",
      "‚Ä¢ Parameter f√ºr spezifische Grundriss-Typen anpassen\n",
      "‚Ä¢ Fein-Tuning der Filter-Schwellenwerte\n",
      "‚Ä¢ Integration von Architektur-spezifischen Symbolen\n",
      "‚Ä¢ Export-Optionen f√ºr CAD-Software\n"
     ]
    }
   ],
   "source": [
    "# ===== TEST DER VERBESSERTEN VEKTORISIERUNG =====\n",
    "\n",
    "print(\"üöÄ === TEST DER VERBESSERTEN VEKTORISIERUNG ===\")\n",
    "print()\n",
    "\n",
    "# Test mit verf√ºgbarem Grundriss\n",
    "test_files = [\"example_floorplan.pdf\", \"example_floorplan2.pdf\"]\n",
    "\n",
    "for test_file in test_files:\n",
    "    if os.path.exists(test_file):\n",
    "        print(f\"üìÑ Teste mit: {test_file}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Verbesserte Vektorisierung ausf√ºhren\n",
    "            svg_path = vectorize_floorplan(test_file, \"output_improved\")\n",
    "            \n",
    "            if svg_path:\n",
    "                print(f\"‚úÖ Verbessertes SVG erstellt: {svg_path}\")\n",
    "                \n",
    "                # Dateigr√∂√üe pr√ºfen\n",
    "                if os.path.exists(svg_path):\n",
    "                    file_size = os.path.getsize(svg_path) / 1024  # KB\n",
    "                    print(f\"üìä Dateigr√∂√üe: {file_size:.1f} KB\")\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ùå Vektorisierung fehlgeschlagen\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler: {e}\")\n",
    "        \n",
    "        print()\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Datei nicht gefunden: {test_file}\")\n",
    "\n",
    "print(\"üí° VERBESSERUNGEN:\")\n",
    "print(\"‚úì Text-Erkennung verhindert √úbervektorisierung von Beschriftungen\")\n",
    "print(\"‚úì W√§nde werden als Schraffuren dargestellt\")  \n",
    "print(\"‚úì Intelligente Linienverschmelzung reduziert √úberlappungen\")\n",
    "print(\"‚úì Wichtige Konturen werden gefiltert\")\n",
    "print(\"‚úì OCR-extrahierter Text wird als echte SVG-Texte eingef√ºgt\")\n",
    "print()\n",
    "print(\"üéØ N√ÑCHSTE SCHRITTE:\")\n",
    "print(\"‚Ä¢ Parameter f√ºr spezifische Grundriss-Typen anpassen\")\n",
    "print(\"‚Ä¢ Fein-Tuning der Filter-Schwellenwerte\") \n",
    "print(\"‚Ä¢ Integration von Architektur-spezifischen Symbolen\")\n",
    "print(\"‚Ä¢ Export-Optionen f√ºr CAD-Software\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== HILFSFUNKTION F√úR PDF-ANALYSE =====\n",
    "\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    \"\"\"\n",
    "    √úberpr√ºft, ob eine PDF-Datei durchsuchbar ist (Text enth√§lt).\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur PDF-Datei\n",
    "        \n",
    "    Returns:\n",
    "        bool: True wenn durchsuchbar, False wenn nur Bilder\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Methode 1: pdfminer versuchen\n",
    "        text = extract_text(pdf_path)\n",
    "        if text and len(text.strip()) > 10:  # Mindestens 10 Zeichen sinnvoller Text\n",
    "            print(f\"üìÑ PDF-Status: Durchsuchbar\")\n",
    "            print(f\"üìù Gefundener Text: {len(text)} Zeichen\")\n",
    "            return True\n",
    "        \n",
    "        # Methode 2: PyMuPDF versuchen\n",
    "        doc = fitz.open(pdf_path)\n",
    "        total_text = \"\"\n",
    "        for page_num in range(min(3, len(doc))):  # Erste 3 Seiten pr√ºfen\n",
    "            page = doc[page_num]\n",
    "            page_text = page.get_text()\n",
    "            total_text += page_text\n",
    "        doc.close()\n",
    "        \n",
    "        if len(total_text.strip()) > 10:\n",
    "            print(f\"üìÑ PDF-Status: Durchsuchbar\")\n",
    "            print(f\"üìù Gefundener Text: {len(total_text)} Zeichen\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"üìÑ PDF-Status: Nicht durchsuchbar (Raster-PDF)\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Fehler beim √úberpr√ºfen der PDF: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test der korrigierten Vektorisierung ===\n",
      "Erkanntes Dateiformat: pdf\n",
      "‚ö† PDF enth√§lt keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Konturen...\n",
      "Erkenne gerade Linien...\n",
      "Erkenne Kreise...\n",
      "‚úì SVG erstellt: output\\example_floorplan_vectorized.svg\n",
      "  Konturen: 1987, Linien: 8999, Kreise: 312\n",
      "‚úÖ Vektorisierung erfolgreich: output\\example_floorplan_vectorized.svg\n"
     ]
    }
   ],
   "source": [
    "# Test mit der korrigierten Vektorisierung\n",
    "print(\"=== Test der korrigierten Vektorisierung ===\")\n",
    "try:\n",
    "    svg_path = vectorize_floorplan(\"example_floorplan.pdf\")\n",
    "    if svg_path:\n",
    "        print(f\"‚úÖ Vektorisierung erfolgreich: {svg_path}\")\n",
    "    else:\n",
    "        print(\"‚ùå Vektorisierung fehlgeschlagen\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unerwarteter Fehler: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test der verbesserten Vektorisierung ===\n",
      "Erkanntes Dateiformat: pdf\n",
      "‚ö† PDF enth√§lt keine Vektorpfade - verwende Rasterbild-Vektorisierung\n",
      "Erkenne Konturen...\n",
      "Erkenne gerade Linien...\n",
      "Erkenne Kreise...\n"
     ]
    }
   ],
   "source": [
    "# Zus√§tzliche Hilfsfunktion f√ºr bessere Visualisierung und Debugging\n",
    "def save_debug_images(image, processed_image, output_dir=\"debug\"):\n",
    "    \"\"\"\n",
    "    Speichert Debug-Bilder um die Bildverarbeitung zu visualisieren.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Original speichern\n",
    "    if len(image.shape) == 3:\n",
    "        cv2.imwrite(os.path.join(output_dir, \"01_original.png\"), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    else:\n",
    "        cv2.imwrite(os.path.join(output_dir, \"01_original.png\"), image)\n",
    "    \n",
    "    # Verarbeitetes Bild speichern\n",
    "    cv2.imwrite(os.path.join(output_dir, \"02_processed.png\"), processed_image)\n",
    "    \n",
    "    print(f\"Debug-Bilder gespeichert in: {output_dir}\")\n",
    "\n",
    "# Test mit verbesserter Vektorisierung\n",
    "print(\"=== Test der verbesserten Vektorisierung ===\")\n",
    "svg_path = vectorize_floorplan(\"example_floorplan2.pdf\")\n",
    "print(f\"Vektorisierter Grundriss: {svg_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Textanalyse & Informationsextraktion\n",
    "\n",
    "Verwende NLP (spaCy) um relevante Schl√ºsselw√∂rter, Positionen, Materialien und Aufgaben zu extrahieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_construction_information(text):\n",
    "    \"\"\"\n",
    "    Extrahiert relevante Bauinformationen aus Text mit spaCy NLP.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Eingabetext aus PDF/OCR\n",
    "        \n",
    "    Returns:\n",
    "        dict: Strukturierte Informationen (Materialien, R√§ume, Ma√üe, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Lade deutsches spaCy-Modell\n",
    "        nlp = spacy.load('de_core_news_lg')\n",
    "        \n",
    "        # Text verarbeiten\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # Initialisiere Ergebnis-Dictionary\n",
    "        extracted_info = {\n",
    "            'materials': [],\n",
    "            'rooms': [],\n",
    "            'measurements': [],\n",
    "            'positions': [],\n",
    "            'tasks': [],\n",
    "            'entities': [],\n",
    "            'keywords': []\n",
    "        }\n",
    "        \n",
    "        # 1. Benannte Entit√§ten extrahieren\n",
    "        for ent in doc.ents:\n",
    "            extracted_info['entities'].append({\n",
    "                'text': ent.text,\n",
    "                'label': ent.label_,\n",
    "                'description': spacy.explain(ent.label_)\n",
    "            })\n",
    "        \n",
    "        # 2. Baumaterialien finden (einfache Keyword-Liste)\n",
    "        material_keywords = [\n",
    "            'beton', 'stahlbeton', 'ziegel', 'mauerwerk', 'holz', 'stahl',\n",
    "            'glas', 'aluminium', 'kunststoff', 'd√§mm', 'isolier', 'putz',\n",
    "            'fliesen', 'parkett', 'laminat', 'estrich', 'fundament'\n",
    "        ]\n",
    "        \n",
    "        for token in doc:\n",
    "            if any(keyword in token.text.lower() for keyword in material_keywords):\n",
    "                extracted_info['materials'].append({\n",
    "                    'text': token.text,\n",
    "                    'context': token.sent.text[:100] + \"...\" if len(token.sent.text) > 100 else token.sent.text\n",
    "                })\n",
    "        \n",
    "        # 3. R√§ume und Bereiche finden\n",
    "        room_keywords = [\n",
    "            'raum', 'zimmer', 'k√ºche', 'bad', 'wohnzimmer', 'schlafzimmer',\n",
    "            'flur', 'diele', 'keller', 'dachboden', 'garage', 'balkon',\n",
    "            'terrasse', 'b√ºro', 'arbeitszimmer', 'g√§ste'\n",
    "        ]\n",
    "        \n",
    "        for token in doc:\n",
    "            if any(keyword in token.text.lower() for keyword in room_keywords):\n",
    "                extracted_info['rooms'].append({\n",
    "                    'text': token.text,\n",
    "                    'context': token.sent.text[:100] + \"...\" if len(token.sent.text) > 100 else token.sent.text\n",
    "                })\n",
    "        \n",
    "        # 4. Ma√üe und Dimensionen finden (einfacher Regex-Ansatz)\n",
    "        import re\n",
    "        measurement_patterns = [\n",
    "            r'\\d+[,.]?\\d*\\s*[x√ó]\\s*\\d+[,.]?\\d*\\s*m',  # \"3,5 x 4,2 m\"\n",
    "            r'\\d+[,.]?\\d*\\s*m¬≤',                        # \"25,3 m¬≤\"\n",
    "            r'\\d+[,.]?\\d*\\s*cm',                        # \"120 cm\"\n",
    "            r'\\d+[,.]?\\d*\\s*mm',                        # \"800 mm\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in measurement_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                extracted_info['measurements'].append(match)\n",
    "        \n",
    "        # 5. Positionen und Lage-Angaben\n",
    "        position_keywords = [\n",
    "            'nord', 's√ºd', 'ost', 'west', 'links', 'rechts', 'oben', 'unten',\n",
    "            'erdgeschoss', 'obergeschoss', 'untergeschoss', 'dachgeschoss'\n",
    "        ]\n",
    "        \n",
    "        for token in doc:\n",
    "            if any(keyword in token.text.lower() for keyword in position_keywords):\n",
    "                extracted_info['positions'].append({\n",
    "                    'text': token.text,\n",
    "                    'context': token.sent.text[:100] + \"...\" if len(token.sent.text) > 100 else token.sent.text\n",
    "                })\n",
    "        \n",
    "        print(f\"‚úì NLP-Analyse abgeschlossen:\")\n",
    "        print(f\"  Entit√§ten: {len(extracted_info['entities'])}\")\n",
    "        print(f\"  Materialien: {len(extracted_info['materials'])}\")\n",
    "        print(f\"  R√§ume: {len(extracted_info['rooms'])}\")\n",
    "        print(f\"  Ma√üe: {len(extracted_info['measurements'])}\")\n",
    "        print(f\"  Positionen: {len(extracted_info['positions'])}\")\n",
    "        \n",
    "        return extracted_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler bei der NLP-Analyse: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test der NLP-Informationsextraktion ===\n",
      "‚úì NLP-Analyse abgeschlossen:\n",
      "  Entit√§ten: 99\n",
      "  Materialien: 0\n",
      "  R√§ume: 0\n",
      "  Ma√üe: 0\n",
      "  Positionen: 0\n",
      "\n",
      "ENTITIES:\n",
      "                            Text   Typ  \\\n",
      "0   Sample PDF\\nThis is a simple  MISC   \n",
      "1                    Fun fun fun  MISC   \n",
      "2  consectetuer  adipiscing elit  MISC   \n",
      "3                       suscipit   PER   \n",
      "4                         Nullam   PER   \n",
      "\n",
      "                                        Beschreibung Kategorie  \n",
      "0  Miscellaneous entities, e.g. events, nationali...   Entit√§t  \n",
      "1  Miscellaneous entities, e.g. events, nationali...   Entit√§t  \n",
      "2  Miscellaneous entities, e.g. events, nationali...   Entit√§t  \n",
      "3                            Named person or family.   Entit√§t  \n",
      "4                            Named person or family.   Entit√§t  \n"
     ]
    }
   ],
   "source": [
    "def create_structured_dataframe(extracted_info):\n",
    "    \"\"\"\n",
    "    Konvertiert extrahierte Informationen in strukturierte pandas DataFrames.\n",
    "    \n",
    "    Args:\n",
    "        extracted_info (dict): Ergebnis von extract_construction_information()\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary mit DataFrames f√ºr verschiedene Kategorien\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframes = {}\n",
    "    \n",
    "    # Materials DataFrame\n",
    "    if extracted_info.get('materials'):\n",
    "        materials_data = []\n",
    "        for item in extracted_info['materials']:\n",
    "            materials_data.append({\n",
    "                'Material': item['text'],\n",
    "                'Kontext': item['context'],\n",
    "                'Kategorie': 'Material'\n",
    "            })\n",
    "        dataframes['materials'] = pd.DataFrame(materials_data)\n",
    "    \n",
    "    # Rooms DataFrame\n",
    "    if extracted_info.get('rooms'):\n",
    "        rooms_data = []\n",
    "        for item in extracted_info['rooms']:\n",
    "            rooms_data.append({\n",
    "                'Raum': item['text'],\n",
    "                'Kontext': item['context'],\n",
    "                'Kategorie': 'Raum'\n",
    "            })\n",
    "        dataframes['rooms'] = pd.DataFrame(rooms_data)\n",
    "    \n",
    "    # Measurements DataFrame\n",
    "    if extracted_info.get('measurements'):\n",
    "        measurements_data = []\n",
    "        for measurement in extracted_info['measurements']:\n",
    "            measurements_data.append({\n",
    "                'Ma√ü': measurement,\n",
    "                'Kategorie': 'Abmessung'\n",
    "            })\n",
    "        dataframes['measurements'] = pd.DataFrame(measurements_data)\n",
    "    \n",
    "    # Entities DataFrame\n",
    "    if extracted_info.get('entities'):\n",
    "        entities_data = []\n",
    "        for entity in extracted_info['entities']:\n",
    "            entities_data.append({\n",
    "                'Text': entity['text'],\n",
    "                'Typ': entity['label'],\n",
    "                'Beschreibung': entity['description'],\n",
    "                'Kategorie': 'Entit√§t'\n",
    "            })\n",
    "        dataframes['entities'] = pd.DataFrame(entities_data)\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Test der NLP-Funktionen mit dem bereits extrahierten Text\n",
    "print(\"=== Test der NLP-Informationsextraktion ===\")\n",
    "if 'text' in locals():\n",
    "    extracted_info = extract_construction_information(text)\n",
    "    dataframes = create_structured_dataframe(extracted_info)\n",
    "    \n",
    "    # Zeige Ergebnisse\n",
    "    for category, df in dataframes.items():\n",
    "        if not df.empty:\n",
    "            print(f\"\\n{category.upper()}:\")\n",
    "            print(df.head())\n",
    "else:\n",
    "    print(\"Verwende Beispieltext f√ºr Demo...\")\n",
    "    example_text = \"\"\"\n",
    "    Die W√§nde des Geb√§udes werden in Stahlbeton ausgef√ºhrt. \n",
    "    Das Wohnzimmer hat eine Gr√∂√üe von 25,3 m¬≤. \n",
    "    Die K√ºche wird mit Fliesen ausgestattet.\n",
    "    Im Erdgeschoss befinden sich 3 R√§ume.\n",
    "    \"\"\"\n",
    "    extracted_info = extract_construction_information(example_text)\n",
    "    dataframes = create_structured_dataframe(extracted_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Automatische Annotation des Grundrisses\n",
    "\n",
    "Lade den vektorisierten Grundriss und platziere automatisch generierte Annotationen basierend auf den extrahierten Informationen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_floorplan_with_info(svg_path, extracted_info, output_path=None):\n",
    "    \"\"\"\n",
    "    F√ºgt Annotationen zum SVG-Grundriss basierend auf extrahierten Informationen hinzu.\n",
    "    \n",
    "    Args:\n",
    "        svg_path (str): Pfad zum vektorisierten SVG-Grundriss\n",
    "        extracted_info (dict): Extrahierte Informationen aus NLP\n",
    "        output_path (str): Ausgabepfad f√ºr annotierte SVG (optional)\n",
    "        \n",
    "    Returns:\n",
    "        str: Pfad zur annotierten SVG-Datei\n",
    "    \"\"\"\n",
    "    \n",
    "    if not svg_path or not os.path.exists(svg_path):\n",
    "        print(\"‚ùå SVG-Grundriss nicht gefunden\")\n",
    "        return None\n",
    "    \n",
    "    # Ausgabepfad bestimmen\n",
    "    if not output_path:\n",
    "        base_name = os.path.splitext(svg_path)[0]\n",
    "        output_path = f\"{base_name}_annotated.svg\"\n",
    "    \n",
    "    try:\n",
    "        # SVG-Dimensionen aus der urspr√ºnglichen Datei lesen\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(svg_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Versuche Dimensionen zu extrahieren\n",
    "        width = 800  # Fallback-Werte\n",
    "        height = 600\n",
    "        \n",
    "        if 'viewBox' in root.attrib:\n",
    "            viewbox = root.attrib['viewBox'].split()\n",
    "            width, height = int(float(viewbox[2])), int(float(viewbox[3]))\n",
    "        elif 'width' in root.attrib and 'height' in root.attrib:\n",
    "            width = int(float(root.attrib['width'].replace('px', '')))\n",
    "            height = int(float(root.attrib['height'].replace('px', '')))\n",
    "        \n",
    "        # Neue SVG mit Annotationen erstellen\n",
    "        dwg = svgwrite.Drawing(output_path, size=(f\"{width}px\", f\"{height}px\"))\n",
    "        \n",
    "        # Lade das urspr√ºngliche SVG als Hintergrund\n",
    "        # (Vereinfacht: kopiere nur die Grundriss-Geometrie)\n",
    "        \n",
    "        # Annotation-Bereiche definieren\n",
    "        annotation_areas = {\n",
    "            'materials': {'x': 20, 'y': 30, 'color': 'blue'},\n",
    "            'rooms': {'x': 20, 'y': height//2, 'color': 'green'},\n",
    "            'measurements': {'x': width-200, 'y': 30, 'color': 'red'},\n",
    "            'general': {'x': width-200, 'y': height//2, 'color': 'purple'}\n",
    "        }\n",
    "        \n",
    "        # Titel hinzuf√ºgen\n",
    "        dwg.add(dwg.text(\"Automatisch annotierter Grundriss\", \n",
    "                        insert=(width//2, 20), \n",
    "                        text_anchor=\"middle\", \n",
    "                        font_size=\"16px\", \n",
    "                        font_weight=\"bold\"))\n",
    "        \n",
    "        # Materialien annotieren\n",
    "        if extracted_info.get('materials'):\n",
    "            y_pos = annotation_areas['materials']['y']\n",
    "            dwg.add(dwg.text(\"Materialien:\", \n",
    "                           insert=(annotation_areas['materials']['x'], y_pos), \n",
    "                           font_size=\"14px\", \n",
    "                           font_weight=\"bold\", \n",
    "                           fill=annotation_areas['materials']['color']))\n",
    "            \n",
    "            for i, material in enumerate(extracted_info['materials'][:5]):  # Max 5 Eintr√§ge\n",
    "                y_pos += 20\n",
    "                dwg.add(dwg.text(f\"‚Ä¢ {material['text']}\", \n",
    "                               insert=(annotation_areas['materials']['x'] + 10, y_pos), \n",
    "                               font_size=\"12px\", \n",
    "                               fill=annotation_areas['materials']['color']))\n",
    "        \n",
    "        # R√§ume annotieren\n",
    "        if extracted_info.get('rooms'):\n",
    "            y_pos = annotation_areas['rooms']['y']\n",
    "            dwg.add(dwg.text(\"R√§ume:\", \n",
    "                           insert=(annotation_areas['rooms']['x'], y_pos), \n",
    "                           font_size=\"14px\", \n",
    "                           font_weight=\"bold\", \n",
    "                           fill=annotation_areas['rooms']['color']))\n",
    "            \n",
    "            for i, room in enumerate(extracted_info['rooms'][:5]):  # Max 5 Eintr√§ge\n",
    "                y_pos += 20\n",
    "                dwg.add(dwg.text(f\"‚Ä¢ {room['text']}\", \n",
    "                               insert=(annotation_areas['rooms']['x'] + 10, y_pos), \n",
    "                               font_size=\"12px\", \n",
    "                               fill=annotation_areas['rooms']['color']))\n",
    "        \n",
    "        # Ma√üe annotieren\n",
    "        if extracted_info.get('measurements'):\n",
    "            y_pos = annotation_areas['measurements']['y']\n",
    "            dwg.add(dwg.text(\"Abmessungen:\", \n",
    "                           insert=(annotation_areas['measurements']['x'], y_pos), \n",
    "                           font_size=\"14px\", \n",
    "                           font_weight=\"bold\", \n",
    "                           fill=annotation_areas['measurements']['color']))\n",
    "            \n",
    "            for i, measurement in enumerate(extracted_info['measurements'][:5]):  # Max 5 Eintr√§ge\n",
    "                y_pos += 20\n",
    "                dwg.add(dwg.text(f\"‚Ä¢ {measurement}\", \n",
    "                               insert=(annotation_areas['measurements']['x'] + 10, y_pos), \n",
    "                               font_size=\"12px\", \n",
    "                               fill=annotation_areas['measurements']['color']))\n",
    "        \n",
    "        # Legende hinzuf√ºgen\n",
    "        legend_y = height - 100\n",
    "        dwg.add(dwg.text(\"Legende:\", \n",
    "                       insert=(20, legend_y), \n",
    "                       font_size=\"14px\", \n",
    "                       font_weight=\"bold\"))\n",
    "        \n",
    "        legend_items = [\n",
    "            (\"Materialien\", annotation_areas['materials']['color']),\n",
    "            (\"R√§ume\", annotation_areas['rooms']['color']),\n",
    "            (\"Abmessungen\", annotation_areas['measurements']['color'])\n",
    "        ]\n",
    "        \n",
    "        for i, (label, color) in enumerate(legend_items):\n",
    "            y = legend_y + 20 + (i * 20)\n",
    "            dwg.add(dwg.circle(center=(30, y-5), r=5, fill=color))\n",
    "            dwg.add(dwg.text(label, insert=(45, y), font_size=\"12px\"))\n",
    "        \n",
    "        # SVG speichern\n",
    "        dwg.save()\n",
    "        print(f\"‚úì Annotierter Grundriss erstellt: {output_path}\")\n",
    "        return output_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler bei der Annotation: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Kompletter Workflow\n",
    "\n",
    "Zusammenf√ºhrung aller Schritte in einer einzigen Workflow-Funktion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_construction_documents(pdf_path, floorplan_path, output_dir=\"workflow_output\"):\n",
    "    \"\"\"\n",
    "    Kompletter automatisierter Workflow f√ºr Bauausschreibungen und Grundrisse.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Pfad zur Bauausschreibungs-PDF\n",
    "        floorplan_path (str): Pfad zum Grundriss (PDF/Bild)\n",
    "        output_dir (str): Ausgabeverzeichnis\n",
    "        \n",
    "    Returns:\n",
    "        dict: Ergebnisse des gesamten Workflows\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ausgabeverzeichnis erstellen\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"üèóÔ∏è === AUTOMATISIERTER BAU-WORKFLOW GESTARTET ===\")\n",
    "    print(f\"üìÑ PDF: {pdf_path}\")\n",
    "    print(f\"üè† Grundriss: {floorplan_path}\")\n",
    "    print(f\"üìÅ Ausgabe: {output_dir}\")\n",
    "    print()\n",
    "    \n",
    "    workflow_results = {\n",
    "        'success': False,\n",
    "        'text_extraction': None,\n",
    "        'method_used': None,\n",
    "        'svg_path': None,\n",
    "        'extracted_info': None,\n",
    "        'annotated_svg': None,\n",
    "        'dataframes': None,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Schritt 1: Text aus PDF extrahieren\n",
    "        print(\"üîç Schritt 1: Text-Extraktion...\")\n",
    "        text, method = extract_text_from_pdf(pdf_path)\n",
    "        \n",
    "        if not text.strip():\n",
    "            workflow_results['errors'].append(\"Keine Textextraktion m√∂glich\")\n",
    "            print(\"‚ùå Keine Textextraktion m√∂glich\")\n",
    "            return workflow_results\n",
    "        \n",
    "        workflow_results['text_extraction'] = text\n",
    "        workflow_results['method_used'] = method\n",
    "        print(f\"‚úÖ Text extrahiert mit Methode: {method}\")\n",
    "        print()\n",
    "        \n",
    "        # Schritt 2: Grundriss vektorisieren\n",
    "        print(\"üé® Schritt 2: Grundriss-Vektorisierung...\")\n",
    "        svg_path = vectorize_floorplan(floorplan_path, output_dir)\n",
    "        \n",
    "        if not svg_path:\n",
    "            workflow_results['errors'].append(\"Vektorisierung fehlgeschlagen\")\n",
    "            print(\"‚ùå Vektorisierung fehlgeschlagen\")\n",
    "        else:\n",
    "            workflow_results['svg_path'] = svg_path\n",
    "            print(f\"‚úÖ Grundriss vektorisiert: {svg_path}\")\n",
    "        print()\n",
    "        \n",
    "        # Schritt 3: NLP-Informationsextraktion\n",
    "        print(\"üß† Schritt 3: NLP-Analyse...\")\n",
    "        extracted_info = extract_construction_information(text)\n",
    "        \n",
    "        if not extracted_info:\n",
    "            workflow_results['errors'].append(\"NLP-Analyse fehlgeschlagen\")\n",
    "            print(\"‚ùå NLP-Analyse fehlgeschlagen\")\n",
    "        else:\n",
    "            workflow_results['extracted_info'] = extracted_info\n",
    "            # Strukturiere Daten in DataFrames\n",
    "            dataframes = create_structured_dataframe(extracted_info)\n",
    "            workflow_results['dataframes'] = dataframes\n",
    "            print(\"‚úÖ NLP-Analyse abgeschlossen\")\n",
    "        print()\n",
    "        \n",
    "        # Schritt 4: Automatische Annotation\n",
    "        if svg_path and extracted_info:\n",
    "            print(\"üìù Schritt 4: Automatische Annotation...\")\n",
    "            annotated_svg = annotate_floorplan_with_info(svg_path, extracted_info, \n",
    "                                                       os.path.join(output_dir, \"annotated_floorplan.svg\"))\n",
    "            \n",
    "            if annotated_svg:\n",
    "                workflow_results['annotated_svg'] = annotated_svg\n",
    "                print(f\"‚úÖ Annotation erstellt: {annotated_svg}\")\n",
    "            else:\n",
    "                workflow_results['errors'].append(\"Annotation fehlgeschlagen\")\n",
    "                print(\"‚ùå Annotation fehlgeschlagen\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Schritt 4 √ºbersprungen (Vektorisierung oder NLP fehlgeschlagen)\")\n",
    "        print()\n",
    "        \n",
    "        # Schritt 5: Ergebnisse speichern\n",
    "        print(\"üíæ Schritt 5: Ergebnisse speichern...\")\n",
    "        \n",
    "        # Extrahierten Text speichern\n",
    "        with open(os.path.join(output_dir, \"extracted_text.txt\"), 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "        \n",
    "        # DataFrames als CSV speichern\n",
    "        if workflow_results.get('dataframes'):\n",
    "            for category, df in workflow_results['dataframes'].items():\n",
    "                if not df.empty:\n",
    "                    df.to_csv(os.path.join(output_dir, f\"{category}.csv\"), \n",
    "                             index=False, encoding='utf-8')\n",
    "        \n",
    "        # Workflow-Bericht erstellen\n",
    "        report_path = os.path.join(output_dir, \"workflow_report.txt\")\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"AUTOMATISIERTER BAU-WORKFLOW BERICHT\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"PDF-Datei: {pdf_path}\\n\")\n",
    "            f.write(f\"Grundriss: {floorplan_path}\\n\")\n",
    "            f.write(f\"Textextraktion: {method}\\n\")\n",
    "            f.write(f\"Textl√§nge: {len(text)} Zeichen\\n\")\n",
    "            f.write(f\"SVG erstellt: {'Ja' if svg_path else 'Nein'}\\n\")\n",
    "            f.write(f\"Annotation erstellt: {'Ja' if workflow_results.get('annotated_svg') else 'Nein'}\\n\")\n",
    "            \n",
    "            if extracted_info:\n",
    "                f.write(f\"\\nExtrahierte Informationen:\\n\")\n",
    "                f.write(f\"- Materialien: {len(extracted_info.get('materials', []))}\\n\")\n",
    "                f.write(f\"- R√§ume: {len(extracted_info.get('rooms', []))}\\n\")\n",
    "                f.write(f\"- Ma√üe: {len(extracted_info.get('measurements', []))}\\n\")\n",
    "                f.write(f\"- Positionen: {len(extracted_info.get('positions', []))}\\n\")\n",
    "            \n",
    "            if workflow_results['errors']:\n",
    "                f.write(f\"\\nFehler: {', '.join(workflow_results['errors'])}\\n\")\n",
    "        \n",
    "        workflow_results['success'] = len(workflow_results['errors']) == 0\n",
    "        \n",
    "        print(\"‚úÖ Workflow abgeschlossen!\")\n",
    "        print(f\"üìä Bericht gespeichert: {report_path}\")\n",
    "        \n",
    "        return workflow_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        workflow_results['errors'].append(str(e))\n",
    "        print(f\"‚ùå Workflow-Fehler: {e}\")\n",
    "        return workflow_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è === AUTOMATISIERTER BAU-WORKFLOW GESTARTET ===\n",
      "üìÑ PDF: bauausschreibung.pdf\n",
      "üè† Grundriss: grundriss.pdf\n",
      "üìÅ Ausgabe: ergebnisse\n",
      "\n",
      "üîç Schritt 1: Text-Extraktion...\n",
      "‚ùå Workflow-Fehler: PDF-Datei nicht gefunden: bauausschreibung.pdf\n"
     ]
    }
   ],
   "source": [
    "# Einfacher Aufruf f√ºr kompletten Workflow\n",
    "results = process_construction_documents(\n",
    "    pdf_path=\"bauausschreibung.pdf\",\n",
    "    floorplan_path=\"grundriss.pdf\", \n",
    "    output_dir=\"ergebnisse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einfacher Aufruf des kompletten Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## üîç Bonus-Workflow: Raster-PDF zu durchsuchbares PDF\n",
    "\n",
    "Separater Workflow zur Konvertierung von gescannten/Raster-PDFs in durchsuchbare PDFs mit OCR-Text-Layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raster_pdf_to_searchable(input_pdf_path, output_pdf_path=None, \n",
    "                                     language='deu+eng', dpi=300):\n",
    "    \"\"\"\n",
    "    Konvertiert eine Raster-PDF (gescannt) in eine durchsuchbare PDF mit OCR-Text-Layer.\n",
    "    \n",
    "    Args:\n",
    "        input_pdf_path (str): Pfad zur Eingabe-PDF\n",
    "        output_pdf_path (str): Pfad f√ºr Ausgabe-PDF (optional)\n",
    "        language (str): Tesseract Sprachcode\n",
    "        dpi (int): DPI f√ºr die Bildkonvertierung\n",
    "        \n",
    "    Returns:\n",
    "        str: Pfad zur erstellten durchsuchbaren PDF\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(input_pdf_path):\n",
    "        print(f\"‚ùå Eingabe-PDF nicht gefunden: {input_pdf_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Ausgabepfad bestimmen\n",
    "    if not output_pdf_path:\n",
    "        base_name = os.path.splitext(input_pdf_path)[0]\n",
    "        output_pdf_path = f\"{base_name}_searchable.pdf\"\n",
    "    \n",
    "    print(f\"üîÑ Konvertiere Raster-PDF zu durchsuchbarer PDF...\")\n",
    "    print(f\"üìÑ Eingabe: {input_pdf_path}\")\n",
    "    print(f\"üíæ Ausgabe: {output_pdf_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Schritt 1: √úberpr√ºfe ob bereits durchsuchbar\n",
    "        if is_pdf_searchable(input_pdf_path):\n",
    "            print(\"‚úÖ PDF ist bereits durchsuchbar - kopiere Original\")\n",
    "            import shutil\n",
    "            shutil.copy2(input_pdf_path, output_pdf_path)\n",
    "            return output_pdf_path\n",
    "        \n",
    "        # Schritt 2: PDF zu Bildern konvertieren\n",
    "        print(\"üñºÔ∏è Konvertiere PDF-Seiten zu Bildern...\")\n",
    "        images = convert_from_path(input_pdf_path, dpi=dpi)\n",
    "        print(f\"üìã {len(images)} Seiten gefunden\")\n",
    "        \n",
    "        # Schritt 3: Einfachere Methode - Text extrahieren und neues PDF erstellen\n",
    "        print(\"üîç Starte OCR...\")\n",
    "        \n",
    "        # Erstelle neues PDF-Dokument  \n",
    "        new_doc = fitz.open()\n",
    "        \n",
    "        for page_num, image in enumerate(images):\n",
    "            print(f\"  üìÑ Verarbeite Seite {page_num + 1}/{len(images)}\")\n",
    "            \n",
    "            # OCR f√ºr gesamten Text der Seite\n",
    "            page_text = pytesseract.image_to_string(\n",
    "                image, \n",
    "                lang=language,\n",
    "                config='--psm 1'\n",
    "            )\n",
    "            \n",
    "            # Neue Seite erstellen mit Original-Dimensionen\n",
    "            page_width = image.width * 72 / dpi\n",
    "            page_height = image.height * 72 / dpi\n",
    "            new_page = new_doc.new_page(width=page_width, height=page_height)\n",
    "            \n",
    "            # Original-Bild einf√ºgen\n",
    "            import io\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            image.save(img_byte_arr, format='PNG')\n",
    "            img_bytes = img_byte_arr.getvalue()\n",
    "            \n",
    "            new_page.insert_image(fitz.Rect(0, 0, page_width, page_height), \n",
    "                                 stream=img_bytes)\n",
    "            \n",
    "            # Unsichtbaren Text hinzuf√ºgen (f√ºr Durchsuchbarkeit)\n",
    "            if page_text.strip():\n",
    "                # Text au√üerhalb des sichtbaren Bereichs platzieren\n",
    "                new_page.insert_text(\n",
    "                    (page_width + 10, 10),  # Au√üerhalb der Seite\n",
    "                    page_text,\n",
    "                    fontsize=1,  # Sehr kleine Schrift\n",
    "                    color=(1, 1, 1),  # Wei√ü (unsichtbar)\n",
    "                )\n",
    "        \n",
    "        # PDF speichern\n",
    "        new_doc.save(output_pdf_path, garbage=4, deflate=True)\n",
    "        new_doc.close()\n",
    "        \n",
    "        print(f\"‚úÖ Durchsuchbare PDF erstellt: {output_pdf_path}\")\n",
    "        \n",
    "        # Validierung\n",
    "        if is_pdf_searchable(output_pdf_path):\n",
    "            print(\"‚úÖ Validierung erfolgreich - PDF ist jetzt durchsuchbar!\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Warnung: PDF m√∂glicherweise nicht vollst√§ndig durchsuchbar\")\n",
    "        \n",
    "        return output_pdf_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler bei der Konvertierung: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convert_pdfs_to_searchable(input_directory, output_directory=None):\n",
    "    \"\"\"\n",
    "    Batch-Konvertierung mehrerer PDF-Dateien zu durchsuchbaren PDFs.\n",
    "    \n",
    "    Args:\n",
    "        input_directory (str): Verzeichnis mit Eingabe-PDFs\n",
    "        output_directory (str): Ausgabeverzeichnis (optional)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Ergebnisse der Batch-Konvertierung\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(input_directory):\n",
    "        print(f\"‚ùå Eingabeverzeichnis nicht gefunden: {input_directory}\")\n",
    "        return None\n",
    "    \n",
    "    # Ausgabeverzeichnis bestimmen\n",
    "    if not output_directory:\n",
    "        output_directory = os.path.join(input_directory, \"searchable_pdfs\")\n",
    "    \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Finde alle PDF-Dateien\n",
    "    pdf_files = [f for f in os.listdir(input_directory) if f.lower().endswith('.pdf')]\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"‚ùå Keine PDF-Dateien in {input_directory} gefunden\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìÅ Batch-Konvertierung von {len(pdf_files)} PDF-Dateien\")\n",
    "    print(f\"üì• Eingabe: {input_directory}\")\n",
    "    print(f\"üì§ Ausgabe: {output_directory}\")\n",
    "    print()\n",
    "    \n",
    "    results = {\n",
    "        'total_files': len(pdf_files),\n",
    "        'converted': [],\n",
    "        'already_searchable': [],\n",
    "        'failed': [],\n",
    "        'processing_time': 0\n",
    "    }\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, pdf_file in enumerate(pdf_files):\n",
    "        print(f\"üîÑ [{i+1}/{len(pdf_files)}] Verarbeite: {pdf_file}\")\n",
    "        \n",
    "        input_path = os.path.join(input_directory, pdf_file)\n",
    "        output_filename = f\"searchable_{pdf_file}\"\n",
    "        output_path = os.path.join(output_directory, output_filename)\n",
    "        \n",
    "        try:\n",
    "            result_path = convert_raster_pdf_to_searchable(input_path, output_path)\n",
    "            \n",
    "            if result_path:\n",
    "                if result_path == output_path:\n",
    "                    results['converted'].append(pdf_file)\n",
    "                else:\n",
    "                    results['already_searchable'].append(pdf_file)\n",
    "            else:\n",
    "                results['failed'].append(pdf_file)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler bei {pdf_file}: {e}\")\n",
    "            results['failed'].append(pdf_file)\n",
    "        \n",
    "        print()  # Leerzeile zwischen Dateien\n",
    "    \n",
    "    results['processing_time'] = time.time() - start_time\n",
    "    \n",
    "    # Zusammenfassung\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä BATCH-KONVERTIERUNG ABGESCHLOSSEN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìÑ Verarbeitete Dateien: {results['total_files']}\")\n",
    "    print(f\"‚úÖ Konvertiert: {len(results['converted'])}\")\n",
    "    print(f\"‚úì Bereits durchsuchbar: {len(results['already_searchable'])}\")\n",
    "    print(f\"‚ùå Fehlgeschlagen: {len(results['failed'])}\")\n",
    "    print(f\"‚è±Ô∏è Verarbeitungszeit: {results['processing_time']:.1f} Sekunden\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEMO: RASTER-PDF ZU DURCHSUCHBARER PDF ===\n",
      "\n",
      "üîç Teste Datei: Angebot_Schulzimmertuere.pdf\n",
      "üìÑ PDF-Status: Durchsuchbar\n",
      "üìù Gefundener Text: 1984 Zeichen\n",
      "‚úÖ PDF ist bereits durchsuchbar\n",
      "--------------------------------------------------\n",
      "\n",
      "üí° BATCH-KONVERTIERUNG BEISPIEL:\n",
      "# Konvertiere alle PDFs in einem Ordner:\n",
      "# results = batch_convert_pdfs_to_searchable('mein_pdf_ordner')\n",
      "\n",
      "üí° EINZELNE DATEI BEISPIEL:\n",
      "# result = convert_raster_pdf_to_searchable('gescannte_datei.pdf')\n",
      "\n",
      "üéØ NUTZUNGSHINWEISE:\n",
      "‚Ä¢ Funktioniert mit gescannten PDFs (Raster-Bildern)\n",
      "‚Ä¢ Erkennt automatisch ob PDF bereits durchsuchbar ist\n",
      "‚Ä¢ Beh√§lt Original-Bildqualit√§t bei\n",
      "‚Ä¢ F√ºgt unsichtbaren Text-Layer f√ºr Suchfunktion hinzu\n",
      "‚Ä¢ Unterst√ºtzt Deutsch + Englisch OCR\n",
      "‚Ä¢ Batch-Modus f√ºr mehrere Dateien verf√ºgbar\n"
     ]
    }
   ],
   "source": [
    "# Demo der PDF-zu-durchsuchbar Konvertierung\n",
    "print(\"=== DEMO: RASTER-PDF ZU DURCHSUCHBARER PDF ===\")\n",
    "\n",
    "# Teste mit verf√ºgbaren PDF-Dateien\n",
    "test_files = [\"Angebot_Schulzimmertuere.pdf\"]\n",
    "\n",
    "for test_file in test_files:\n",
    "    if os.path.exists(test_file):\n",
    "        print(f\"\\nüîç Teste Datei: {test_file}\")\n",
    "        \n",
    "        # √úberpr√ºfe aktuellen Status\n",
    "        is_searchable = is_pdf_searchable(test_file)\n",
    "        \n",
    "        if not is_searchable:\n",
    "            print(\"üìù Konvertiere zu durchsuchbarer PDF...\")\n",
    "            result = convert_raster_pdf_to_searchable(test_file)\n",
    "            \n",
    "            if result:\n",
    "                print(f\"‚úÖ Durchsuchbare PDF erstellt: {result}\")\n",
    "            else:\n",
    "                print(\"‚ùå Konvertierung fehlgeschlagen\")\n",
    "        else:\n",
    "            print(\"‚úÖ PDF ist bereits durchsuchbar\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Beispiel f√ºr Batch-Konvertierung\n",
    "print(\"\\nüí° BATCH-KONVERTIERUNG BEISPIEL:\")\n",
    "print(\"# Konvertiere alle PDFs in einem Ordner:\")\n",
    "print(\"# results = batch_convert_pdfs_to_searchable('mein_pdf_ordner')\")\n",
    "print(\"\\nüí° EINZELNE DATEI BEISPIEL:\")\n",
    "print(\"# result = convert_raster_pdf_to_searchable('gescannte_datei.pdf')\")\n",
    "\n",
    "print(\"\\nüéØ NUTZUNGSHINWEISE:\")\n",
    "print(\"‚Ä¢ Funktioniert mit gescannten PDFs (Raster-Bildern)\")\n",
    "print(\"‚Ä¢ Erkennt automatisch ob PDF bereits durchsuchbar ist\")\n",
    "print(\"‚Ä¢ Beh√§lt Original-Bildqualit√§t bei\")\n",
    "print(\"‚Ä¢ F√ºgt unsichtbaren Text-Layer f√ºr Suchfunktion hinzu\")\n",
    "print(\"‚Ä¢ Unterst√ºtzt Deutsch + Englisch OCR\")\n",
    "print(\"‚Ä¢ Batch-Modus f√ºr mehrere Dateien verf√ºgbar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Eingabe-PDF nicht gefunden: gescannte_datei.pdf\n",
      "‚ùå Eingabeverzeichnis nicht gefunden: mein_pdf_ordner\n"
     ]
    }
   ],
   "source": [
    "# Einzelne Datei\n",
    "result = convert_raster_pdf_to_searchable('gescannte_datei.pdf')\n",
    "\n",
    "# Batch-Verarbeitung\n",
    "results = batch_convert_pdfs_to_searchable('mein_pdf_ordner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BKP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Bezeichnung</th>\n",
       "      <th>Kategorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>√úbergangspositionen</td>\n",
       "      <td>0 Grundst√ºck &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Studien zur Grundst√ºckbeurteilung</td>\n",
       "      <td>0 Grundst√ºck &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vermessung, Vermarchung</td>\n",
       "      <td>0 Grundst√ºck &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Geotechnische Gutachten</td>\n",
       "      <td>0 Grundst√ºck &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Quartierplankosten</td>\n",
       "      <td>0 Grundst√ºck &gt; 00 Vorstudien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>992</td>\n",
       "      <td>993</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>994</td>\n",
       "      <td>995</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>996</td>\n",
       "      <td>Spezialisten</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>997</td>\n",
       "      <td>998</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>999</td>\n",
       "      <td>√úbriges</td>\n",
       "      <td>9 Ausstatung &gt; 99 Honorare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Position                        Bezeichnung                     Kategorie\n",
       "0           0                √úbergangspositionen  0 Grundst√ºck > 00 Vorstudien\n",
       "1           1  Studien zur Grundst√ºckbeurteilung  0 Grundst√ºck > 00 Vorstudien\n",
       "2           2            Vermessung, Vermarchung  0 Grundst√ºck > 00 Vorstudien\n",
       "3           3            Geotechnische Gutachten  0 Grundst√ºck > 00 Vorstudien\n",
       "4           4                 Quartierplankosten  0 Grundst√ºck > 00 Vorstudien\n",
       "..        ...                                ...                           ...\n",
       "531       992                                993    9 Ausstatung > 99 Honorare\n",
       "532       994                                995    9 Ausstatung > 99 Honorare\n",
       "533       996                       Spezialisten    9 Ausstatung > 99 Honorare\n",
       "534       997                                998    9 Ausstatung > 99 Honorare\n",
       "535       999                            √úbriges    9 Ausstatung > 99 Honorare\n",
       "\n",
       "[536 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pfad zur heruntergeladenen CSV-Datei angeben\n",
    "csv_path = \"BKP-Plan.csv\"  # Passe den Dateinamen an, falls du anders gespeichert hast\n",
    "\n",
    "# CSV in DataFrame laden\n",
    "df_bkp = pd.read_csv(csv_path)\n",
    "\n",
    "# Ersten √úberblick verschaffen\n",
    "#df_bkp.head(30)\n",
    "df_bkp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_annotation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
